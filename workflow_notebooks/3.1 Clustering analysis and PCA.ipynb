{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering analysis and PCA #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Please make sure that you are using the R kernel to run this notebook.###\n",
    "We are now switching from the bash kernel to the R kernel. \n",
    "The R language provides a number of utilities for genomic data analysis and visualization. We will explore some of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The preprocessCore library provides a number of functions useful for statistical analysis,\n",
    "#including functions for data normalization that we will use below. \n",
    "library(\"preprocessCore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change to your $WORK_DIR. The syntax for switching directories in R is a little different than what we used in bash. \n",
    "#Use the \"setwd\" command to switch to your $WORK_DIR \n",
    "sunetid=\"ambenj\"\n",
    "setwd(paste(\"/srv/scratch/training_camp/work/\",sunetid,sep=\"\"))\n",
    "#The \"dir\" command will list all files in your current working directory \n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will focus on the clustering and PCA analysis steps of the pipeline: \n",
    "![Analysis pipeline](images/part3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the fc signal matrix\n",
    "fc_data=read.table(\"all.fc.txt\",header=TRUE)\n",
    "rownames(fc_data)=paste(fc_data$Chrom,fc_data$Start,fc_data$End,sep='\\t')\n",
    "#remove the columns we will not use in downstream analysis\n",
    "fc_data$ID=NULL\n",
    "fc_data$Chrom=NULL\n",
    "fc_data$Start=NULL\n",
    "fc_data$End=NULL\n",
    "\n",
    "head(fc_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalize the data \n",
    "#quantile normalization \n",
    "fc_data_matrix=normalize.quantiles(data.matrix(asinh(fc_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames(fc_data_matrix)=names(fc_data)\n",
    "rownames(fc_data_matrix)=rownames(fc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head(fc_data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the matrix of read counts for each peak using the same series of commands as we used above for the fold change data matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the read count matrix\n",
    "count_data=read.table(\"all.readcount.txt\",header=TRUE)\n",
    "rownames(count_data)=paste(count_data$Chrom,count_data$Start,count_data$End,sep='\\t')\n",
    "#remove the columns we will not use \n",
    "count_data$Chrom=NULL\n",
    "count_data$Start=NULL\n",
    "count_data$End=NULL\n",
    "count_data$ID=NULL\n",
    "head(count_data)\n",
    "\n",
    "#quantile normalize \n",
    "count_data_matrix=normalize.quantiles(data.matrix(asinh(count_data)))\n",
    "colnames(count_data_matrix)=names(count_data)\n",
    "rownames(count_data_matrix)=rownames(count_data)\n",
    "head(count_data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! After quantile normalization, the read counts and fold change values across samples are on the same scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing R packages##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the scripts in this section, if you get an error saying the gplots package has not been installed, you can install the package locally by  running the **3.5 Install R packages** notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering of Fold Change Signal Across Samples ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster analysis is a simple way to visualize patterns in the data. By clustering peaks according to their signal across different time points, we may find groups of peaks that have similar behavior across these time points. By clustering samples according to their signal across peaks, we can perform a simple sanity check of data quality ‚Äê samples of the same time point should cluster together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(gplots)\n",
    "library(RColorBrewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heatmap.2(fc_data_matrix,\n",
    "          scale     = \"none\",\n",
    "          col       = rev(colorRampPalette(brewer.pal(10, \"RdBu\"))(256)),\n",
    "          distfun   = function(x) dist(x,method=\"euclidean\"),\n",
    "          hclustfun = function(x) hclust(x, method=\"ward.D\"),\n",
    "          Rowv=TRUE,\n",
    "          Colv=TRUE,\n",
    "          dendrogram = \"none\",\n",
    "          trace=\"none\",\n",
    "          cexCol = 0.9,\n",
    "          margins=c(15,5),\n",
    "          labRow=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heatmap.2(count_data_matrix,\n",
    "          scale     = \"none\",\n",
    "          col       = rev(colorRampPalette(brewer.pal(10, \"RdBu\"))(256)),\n",
    "          distfun   = function(x) dist(x,method=\"euclidean\"),\n",
    "          hclustfun = function(x) hclust(x, method=\"ward.D\"),\n",
    "          Rowv=TRUE,\n",
    "          Colv=TRUE,\n",
    "          dendrogram = \"none\",\n",
    "          trace=\"none\",\n",
    "          cexCol = 0.9,\n",
    "          margins=c(15,5),\n",
    "          labRow=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) is a way to identify the primary directions of variation in the data. It can also be used for very coarse-grained clustering of samples; similar samples will have similar coordinates along the principal axes.\n",
    "\n",
    "We will perform PCA on *all.fc.txt*. We treat each sample as a single point in a very high dimensional space (where the dimensionality is equal to the number of genes the vary), and then we will perform dimensionality reduction in this space. We can color-code the PCA plots by \"Strain\", \"Media\", \"Researcher\", or \"Rep\" to determine which parameter separates the samples most effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We run the principle component analysis command in R\n",
    "\n",
    "#The t() function transposes the data matrix and allows us to cluster the samples, as opposed to the individual peaks,\n",
    "#by placing the samples in the rows and the peaks in the columns. \n",
    "fc.pca=prcomp(t(fc_data_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a scree plot that shows how much variance in the data is explained by each prinicipal component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_explained=round(100*fc.pca$sdev^2/sum(fc.pca$sdev^2),2)\n",
    "print(var_explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a simple bar graph to better illustrate the variance explained by each PC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barplot(var_explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the first few prinicpal components to see if they correlate with any of our experimental variables: \n",
    "\n",
    "    * Strain of yeast \n",
    "    * Media \n",
    "    \n",
    "We also expect replicates for the same sample to cluster closely together.\n",
    "\n",
    "Finally, we should make sure to check for any unintended batch effects in the data. For example, it's posssible that samples generated by one researcher may exhibit a systematic difference from samples generated by a different researcher. We should check for this bias and correct it if possible. \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First, we load our metadata file into R to help us color samples by replicate, strain, media, and researcher. \n",
    "metadata=read.table(\"/srv/scratch/training_camp/metadata/TC2017_samples.tsv\",header=TRUE)\n",
    "#We use the \"factor\" function to tell R which variables are categorical rather than continuous \n",
    "metadata$Strain=factor(metadata$Strain)\n",
    "metadata$Media=factor(metadata$Media)\n",
    "metadata$Sample=factor(metadata$Sample)\n",
    "metadata$Researcher=factor(metadata$Researcher)\n",
    "head(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract the PC columns from the fc.pca object \n",
    "pcs=data.frame(fc.pca$x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#add columns from the metadata file. Do this safely using the \"merge\" command to make sure the sample ID's \n",
    "#from the two data frames are aligned\n",
    "pcs$ID=rownames(pcs)\n",
    "pcs_annotated=merge(pcs,metadata,by=\"ID\")\n",
    "head(pcs_annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the ggplot package in R to generate scatterplots of PC1 vs PC2, PC2 vs PC3, etc and color-code\n",
    "by experimental variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot pc1 vs pc2, color by Sample -- that is, all replicates for the same sample should be the same color. \n",
    "ggplot(data=pcs_annotated,aes(x=PC1,y=PC2,color=Sample))+\n",
    "geom_point()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see replicates of the same sample clustering close together. Do we see this in the scatterplot above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Plot pc1 vs pc2, color by Strain \n",
    "ggplot(data=pcs_annotated,aes(x=PC1,y=PC2,color=Strain))+\n",
    "geom_point()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot tells us that principle component 2 (PC2) captures variance in the dataset due to strain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot pc1 vs pc2, color by Media \n",
    "ggplot(data=pcs_annotated,aes(x=PC1,y=PC2,color=Media))+\n",
    "geom_point()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Principal component 1 (PC1) captures variation in the data due to media. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot pc1 vs pc2, color by Researcher -- here, we're checking for a batch effect based on researcher.\n",
    "ggplot(data=pcs_annotated,aes(x=PC1,y=PC2,color=Researcher))+\n",
    "geom_point()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! We do seem to have a batch effect based on researcher -- PC1 captures this effect. This is not surprising, as our design was deliberately confounded for replicates 4 - 6. \n",
    "\n",
    "Luckily, there are steps we can take to remove this batch effect. We use the R **limma** package to fit a linear mixed effects model. The explanatory variables are Strain, Media, and Researcher. The output variable is the normalized fold change value in the data matrix. We then subtract out the contribution from \"Researcher\" (the confounding variable) to the output variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(limma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure the row order of the metadata file matches the column order of the fc_data_matrix file. \n",
    "rownames(metadata)=metadata$ID\n",
    "metadata=metadata[colnames(fc_data_matrix),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#design the model using entries from our metadata file \n",
    "mod=model.matrix(~Strain+Media+Researcher,data=metadata)\n",
    "\n",
    "#fit the model to the data \n",
    "fit=lmFit(fc_data_matrix,design=mod)\n",
    "\n",
    "head(coefficients(fit))\n",
    "\n",
    "#We note that column 5 in the model captures the batch effect from the \"Researcher\" variable. We can remove the \n",
    "#contribution of this variable from the data: \n",
    "batch_contribution=coefficients(fit)[,5]%*% t(fit$design[,5])\n",
    "fc_data_matrix_corrected=fc_data_matrix-batch_contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-run the PCA analysis on  fc_data_matrix_corrected to make sure we're no longer observing a batch effect \n",
    "due to researcher.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc.pca.corrected=prcomp(t(fc_data_matrix_corrected))\n",
    "var_explained=round(100*fc.pca.corrected$sdev^2/sum(fc.pca.corrected$sdev^2),2)\n",
    "barplot(var_explained)\n",
    "pcs.corrected=data.frame(fc.pca.corrected$x)\n",
    "pcs.corrected$ID=rownames(pcs.corrected)\n",
    "pcs_annotated.corrected=merge(pcs.corrected,metadata,by=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated.corrected,aes(x=PC1,y=PC2,color=Researcher))+\n",
    "geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We no longer see samples clustering based on the researcher that performed the experiment. Hopefully, we still see the effects from strain and media, let's verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated.corrected,aes(x=PC1,y=PC2,color=Strain))+\n",
    "geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(data=pcs_annotated.corrected,aes(x=PC1,y=PC2,color=Media))+\n",
    "geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, still there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Generate scatterplots for PC1 vs PC3, and PC2 vs PC3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'd like to determine how much each peak contributes to PC1, PC2, and PC3. We can look at PC4 and up also, but for the sake of time we'll stick with the first 3 principal components; from the scree plot, we see they explain over 50% of the variance in the data. Primarily we want to get a sense of which peaks are critical in defining the principle components, and in which direction (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contribs_pc1=fc.pca.corrected$rotation[,1]\n",
    "contribs_pc2=fc.pca.corrected$rotation[,2]\n",
    "contribs_pc3=fc.pca.corrected$rotation[,3]\n",
    "\n",
    "#these are lists of contributs from each peak to the corresponding PC\n",
    "head(contribs_pc1)\n",
    "length(contribs_pc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use the write.table command to write the PC contribution data to output files. \n",
    "\n",
    "write.table(contribs_pc1,\"pc1_contribs.txt\",quote=FALSE,col.names=FALSE,row.names=TRUE,sep='\\t')\n",
    "write.table(contribs_pc2,\"pc2_contribs.txt\",quote=FALSE,col.names=FALSE,row.names=TRUE,sep='\\t')\n",
    "write.table(contribs_pc3,\"pc3_contribs.txt\",quote=FALSE,col.names=FALSE,row.names=TRUE,sep='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
