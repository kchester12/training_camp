{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Getting ready to run code on the cluster#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Please make sure that your are using the bash kernel to run this notebook.\n",
    "\n",
    "Now that you can submit jobs like any self-respecting Unix ninja, you are ready to start analyzing data! Here you will learn about how to organize your research directory and setup the cluster environment to access all software you wish to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing your research as a pro##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a really nice paper with guidelines on organizing computational projects in an organized and snazzy fashion: (http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000424). Let's see this in action!\n",
    "\n",
    "First, define a variable with the training camp directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/scratch/training_camp/work/ubuntu\r\n"
     ]
    }
   ],
   "source": [
    "export WORKDIR=/srv/scratch/training_camp/work/$(whoami)\n",
    "export WORKDIR=/srv/scratch/training_camp/work/`whoami`\n",
    "\n",
    "echo $WORKDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubuntu\r\n"
     ]
    }
   ],
   "source": [
    "whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize your folder into subdirectories as a pro: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\r\n",
      "mkdir: cannot create directory ‘src’: File exists\r\n",
      "all.fc.bigwig\t\tcln3-SCE-0_6MNaCl-Rep1\tWT-SCD-Rep1\r\n",
      "all.fc.txt\t\tcln3-SCE-0_6MNaCl-Rep2\tWT-SCD-Rep1_out\r\n",
      "all_merged.peaks.bed\tcln3-SCE-Rep1\t\tWT-SCD-Rep1_R1_001.fc.signal\r\n",
      "all_merged.peaks.bed~\tcln3-SCE-Rep2\t\tWT-SCD-Rep1_R1_001.tagAlign\r\n",
      "all.peaks.bed\t\tdata\t\t\tWT-SCD-Rep2\r\n",
      "all.peaks.sorted.bed\tnarrowPeak_files.txt\tWT-SCD-Rep2_out\r\n",
      "all.pval.bigwig\t\tsrc\t\t\tWT-SCD-Rep2_R1_001.fc.signal\r\n",
      "all.pval.txt\t\ttmp\t\t\tWT-SCD-Rep2_R1_001.tagAlign\r\n",
      "all.tagAlign\t\twhi5-cln3-SCE-Rep1\tWT-SCE-0_6MNaCl-Rep1\r\n",
      "all.tagAlign.files.txt\twhi5-cln3-SCE-Rep2\tWT-SCE-0_6MNaCl-Rep2\r\n",
      "cln3-SCD-0_6MNaCl-Rep1\twhi5-SCE-Rep1\t\tWT-SCE-Rep1\r\n",
      "cln3-SCD-0_6MNaCl-Rep2\twhi5-SCE-Rep2\t\tWT-SCE-Rep2\r\n",
      "cln3-SCD-Rep1\t\tWT-SCD-0_6MNaCl-Rep1\r\n",
      "cln3-SCD-Rep2\t\tWT-SCD-0_6MNaCl-Rep2\r\n"
     ]
    }
   ],
   "source": [
    "cd ${WORKDIR}\n",
    "mkdir data src\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cd $WORKDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/scratch/training_camp/work/ubuntu\r\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to run code on the cluster ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data processing will use multiple software tools. To be able to access them, we can load their paths into our session, by loading their respective modules.\n",
    "\n",
    "To load a module, you can type\n",
    "**module load [desiredModule]** - this is going to modify your path\n",
    "\n",
    "Once a module is loaded, you can use the code associated with that module directly. For instance, let's say you want to load a module for BEDTools (a software package we will be using in this training camp). If you run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "source /etc/profile.d/modules.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "module load bedtools/2.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Loaded Modulefiles:\r\n",
      "  1) bedtools/2.17.0\r\n"
     ]
    }
   ],
   "source": [
    "module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It loads the bedtools code, such that when you are ready to use the code, you can just directly call commands. Note that the -h or --help arguments can often be used to give help about a particular tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedtools: flexible tools for genome arithmetic and DNA sequence analysis.\r\n",
      "usage:    bedtools <subcommand> [options]\r\n",
      "\r\n",
      "The bedtools sub-commands include:\r\n",
      "\r\n",
      "[ Genome arithmetic ]\r\n",
      "    intersect     Find overlapping intervals in various ways.\r\n",
      "    window        Find overlapping intervals within a window around an interval.\r\n",
      "    closest       Find the closest, potentially non-overlapping interval.\r\n",
      "    coverage      Compute the coverage over defined intervals.\r\n",
      "    map           Apply a function to a column for each overlapping interval.\r\n",
      "    genomecov     Compute the coverage over an entire genome.\r\n",
      "    merge         Combine overlapping/nearby intervals into a single interval.\r\n",
      "    cluster       Cluster (but don't merge) overlapping/nearby intervals.\r\n",
      "    complement    Extract intervals _not_ represented by an interval file.\r\n",
      "    subtract      Remove intervals based on overlaps b/w two files.\r\n",
      "    slop          Adjust the size of intervals.\r\n",
      "    flank         Create new intervals from the flanks of existing intervals.\r\n",
      "    sort          Order the intervals in a file.\r\n",
      "    random        Generate random intervals in a genome.\r\n",
      "    shuffle       Randomly redistrubute intervals in a genome.\r\n",
      "    annotate      Annotate coverage of features from multiple files.\r\n",
      "\r\n",
      "[ Multi-way file comparisons ]\r\n",
      "    multiinter    Identifies common intervals among multiple interval files.\r\n",
      "    unionbedg     Combines coverage intervals from multiple BEDGRAPH files.\r\n",
      "\r\n",
      "[ Paired-end manipulation ]\r\n",
      "    pairtobed     Find pairs that overlap intervals in various ways.\r\n",
      "    pairtopair    Find pairs that overlap other pairs in various ways.\r\n",
      "\r\n",
      "[ Format conversion ]\r\n",
      "    bamtobed      Convert BAM alignments to BED (& other) formats.\r\n",
      "    bedtobam      Convert intervals to BAM records.\r\n",
      "    bamtofastq    Convert BAM records to FASTQ records.\r\n",
      "    bedpetobam    Convert BEDPE intervals to BAM records.\r\n",
      "    bed12tobed6   Breaks BED12 intervals into discrete BED6 intervals.\r\n",
      "\r\n",
      "[ Fasta manipulation ]\r\n",
      "    getfasta      Use intervals to extract sequences from a FASTA file.\r\n",
      "    maskfasta     Use intervals to mask sequences from a FASTA file.\r\n",
      "    nuc           Profile the nucleotide content of intervals in a FASTA file.\r\n",
      "\r\n",
      "[ BAM focused tools ]\r\n",
      "    multicov      Counts coverage from multiple BAMs at specific intervals.\r\n",
      "    tag           Tag BAM alignments based on overlaps with interval files.\r\n",
      "\r\n",
      "[ Statistics tools ]\r\n",
      "    jaccard       Calculates the Jaccard statistic b/w two sets of intervals.\r\n",
      "\r\n",
      "[ Miscellaneous tools ]\r\n",
      "    overlap       Computes the amount of overlap from two intervals.\r\n",
      "    igv           Create an IGV snapshot batch script.\r\n",
      "    links         Create a HTML page of links to UCSC locations.\r\n",
      "    makewindows   Make interval \"windows\" across a genome.\r\n",
      "    groupby       Group by common cols. & summarize oth. cols. (~ SQL \"groupBy\")\r\n",
      "    expand        Replicate lines based on lists of values in columns.\r\n",
      "\r\n",
      "[ General help ]\r\n",
      "    --help        Print this help menu.\r\n",
      "    --version     What version of bedtools are you using?.\r\n",
      "    --contact     Feature requests, bugs, mailing lists, etc.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "bedtools -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry, you do not need to know off the top of your head the names of the modules you want. To see all software modules available on the AWS cluster, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "------------------------- /usr/share/modules/versions --------------------------\r\n",
      "3.2.10\r\n",
      "\r\n",
      "------------------------ /usr/share/modules/modulefiles ------------------------\r\n",
      "bamtools/default  homer/default     modules           ucsc_tools/2.7.2\r\n",
      "bedtools/2.17.0   java/latest       null              use.own\r\n",
      "bowtie/2.1.0      MACS2/2.0.9       picard-tools/1.95\r\n",
      "dot               module-git        r/3.0.2\r\n",
      "fastqc/0.10.1     module-info       samtools/0.1.19\r\n"
     ]
    }
   ],
   "source": [
    "module avail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The .bashrc file (=your friend) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\r\n",
      "jupyterhub  populate_users.sh  sge_setup  training_camp\r\n",
      ".\t\t.cache\t    .gitconfig\t .login.old\t    sge_setup\r\n",
      "..\t\t.conda\t    .gnupg\t .oracle_jre_usage  .ssh\r\n",
      ".bash_history\t.config     .ipython\t populate_users.sh  training_camp\r\n",
      ".bash_logout\t.continuum  .jupyter\t .profile\t    .viminfo\r\n",
      ".bashrc\t\t.cshrc\t    jupyterhub\t .profile.old\t    .Xauthority\r\n",
      ".bashrc~\t.cshrc.old  .kshenv\t .python-eggs\r\n",
      ".bashrc_backup\t.dbus\t    .kshenv.old  .python_history\r\n",
      ".bashrc.old\t.emacs.d    .local\t .Rprofile\r\n",
      ".bds\t\t.gconf\t    .login\t .selected_editor\r\n"
     ]
    }
   ],
   "source": [
    "#Where is .bashrc?\n",
    "#In our home directory\n",
    "cd ~\n",
    "pwd\n",
    "ls\n",
    "#But this doesn't show bashrc...\n",
    "ls -ah #this does (shows all hidden files)\n",
    "#.bash_logout automatically runs things when you log out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wouldn't it be nice to have everything ready to run when you log into the cluster?\n",
    "To avoid having to run module load commands every time you log in, you can add these commands to a .bashrc file, located in your home directory. The .bashrc file contains a set of commands that get executed every time you log into the server. In this way, every time you log in, you will be all set to run all code you wish.\n",
    "\n",
    "Note: Technically, the ~/.bashrc file is not what's executed on login; it's ~/.bash_profile, which in turn calls ~/.bashrc. If your .bash_profile does not call .bashrc, put the line source ~/.bashrc in your .bash_profile. The difference between the two files is explained here: http://www.joshstaiger.org/archives/2005/07/bash_profile_vs.html\n",
    "\n",
    "Let's add all our desired module loading commands into a .bashrc file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module load bedtools/2.17.0\r\n"
     ]
    }
   ],
   "source": [
    "bedtools_load='module load bedtools/2.17.0'\n",
    "#naive thing:\n",
    "#NOTE: ~ is a shortcut for your home directory\n",
    "#echo $bedtools_load >> ~/.bashrc #this might clutter up our bashrc if we run it a bunch of times\n",
    "\n",
    "#only add the module load commands to the ~/.bashrc file if they don't exist in this file already \n",
    "#The || acts like an OR; it executes the command on the right if the command on the left errors out\n",
    "#grep -E acts like search\n",
    "#reminder: \"$bedtoos_load\" decodes to 'module load bedtools/2.17.0'\n",
    "grep -E \"$bedtools_load\" ~/.bashrc || echo $bedtools_load >> ~/.bashrc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining shortcuts in the .bashrc file ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why stop here? You can make all your dreams come true in the .bashrc file!\n",
    "For instance, you can add to the .bashrc file some shortcuts to your directories of interest, which you can then seamlessly use. Add the following to your .bashrc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#shortcuts_defined:\r\n"
     ]
    }
   ],
   "source": [
    "grep -E \"shortcuts_defined\" ~/.bashrc || \n",
    "(echo '#shortcuts_defined:' >> ~/.bashrc &&\n",
    "\n",
    "echo 'export SUNETID=\"$(whoami)\"' >> ~/.bashrc &&\n",
    "echo 'export WORK_DIR=\"/srv/scratch/training_camp/work/${SUNETID}\"' >> ~/.bashrc &&\n",
    "\n",
    "echo 'export DATA_DIR=\"${WORK_DIR}/data\"' >> ~/.bashrc &&\n",
    "echo '[[ ! -d ${WORK_DIR}/data ]] && mkdir \"${WORK_DIR}/data\"' >> ~/.bashrc &&\n",
    "\n",
    "echo 'export SRC_DIR=\"${WORK_DIR}/src\"' >> ~/.bashrc &&\n",
    "echo '[[ ! -d ${WORK_DIR}/src ]] && mkdir -p \"${WORK_DIR}/src\"' >> ~/.bashrc &&\n",
    "\n",
    "echo 'export METADATA_DIR=\"/srv/scratch/training_camp/metadata\"' >> ~/.bashrc &&\n",
    "echo 'export AGGREGATE_DATA_DIR=\"/srv/scratch/training_camp/data\"' >> ~/.bashrc &&\n",
    "echo 'export AGGREGATE_ANALYSIS_DIR=\"/srv/scratch/training_camp/aggregate_analysis\"' >> ~/.bashrc &&\n",
    "echo 'export YEAST_DIR=\"/srv/scratch/training_camp/saccer3\"' >> ~/.bashrc &&\n",
    "\n",
    "echo 'export TMP=\"${WORK_DIR}/tmp\"' >> ~/.bashrc &&\n",
    "echo 'export TEMP=$TMP' >> ~/.bashrc && \n",
    "echo 'export TMPDIR=$TMP' >> ~/.bashrc && \n",
    "echo '[[ ! -d ${TMP} ]] && mkdir -p \"${TMP}\"' >> ~/.bashrc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\$\\{WORK\\_DIR\\}** is your main work directory\n",
    "\n",
    "**\\$\\{DATA\\_DIR\\}** is your data/ directory -- used for storing the subset of the data you will be working with.  \n",
    "\n",
    "**\\$\\{SRC\\_DIR\\}** is your src/ directory -- used for storing code. \n",
    "\n",
    "**\\$\\{METADATA_DIR}** is the directory with the metadata file for this year's training camp.  \n",
    "\n",
    "\n",
    "**\\$\\{AGGREGATE\\_ANALYSIS\\_DIR}** We will store the aggregate analysis results for all samples in this directory for common use by everyone. \n",
    "\n",
    "**\\$\\{AGGREGATE\\_DATA\\_DIR\\}** is the data/ directory -- this is where we store all the raw data from the sequencer generated by the group\n",
    "\n",
    "**\\$\\{YEAST\\_DIR}** is the directory with the yeast reference genome files \n",
    "\n",
    "**\\$\\{TMP\\_DIR}** is the directory where your temporary files will be stored when you execute code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see your ~/.bashrc and ~/.bash_profile files in action, logout and log in again. All modules should be loaded and all shortcuts should be set!\n",
    "\n",
    "Since logging in/out would disrupt this tutorial, we execute the commands in our ipython notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "export SUNETID=\"$(whoami)\"\n",
    "export WORK_DIR=\"/srv/scratch/training_camp/work/${SUNETID}\"\n",
    "export DATA_DIR=\"${WORK_DIR}/data\"\n",
    "[[ ! -d ${WORK_DIR}/data ]] && mkdir \"${WORK_DIR}/data\"\n",
    "export SRC_DIR=\"${WORK_DIR}/src\"\n",
    "[[ ! -d ${WORK_DIR}/src ]] && mkdir -p \"${WORK_DIR}/src\"\n",
    "export METADATA_DIR=\"/srv/scratch/training_camp/metadata\"\n",
    "export AGGREGATE_DATA_DIR=\"/srv/scratch/training_camp/data\"\n",
    "export AGGREGATE_ANALYSIS_DIR=\"/srv/scratch/training_camp/aggregate_analysis\"\n",
    "export YEAST_DIR=\"/srv/scratch/training_camp/saccer3\"\n",
    "export TMP=\"${WORK_DIR}/tmp\"\n",
    "export TEMP=$TMP\n",
    "export TMPDIR=$TMP\n",
    "[[ ! -d ${TMP} ]] && mkdir -p \"${TMP}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and code for this project ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally good practice to always keep a backup copy of your raw data files in case you unintentionally delete or modify these files when performing your analysis. \n",
    "\n",
    "For this reason, you will copy the two samples you generated from the **\\$AGGREGATE_DATA_DIR** folder to your personal **\\$DATA_DIR** folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#backup data files from 2017\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/WT-SCD-0_6MNaCl-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/WT-SCD-0_6MNaCl-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/WT-SCD-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/WT-SCD-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/WT-SCE-0_6MNaCl-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/WT-SCE-0_6MNaCl-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/WT-SCE-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/WT-SCE-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/cln3-SCD-0_6MNaCl-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/cln3-SCD-0_6MNaCl-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/cln3-SCD-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/cln3-SCD-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/cln3-SCE-0_6MNaCl-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/cln3-SCE-0_6MNaCl-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/cln3-SCE-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/cln3-SCE-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/whi5-SCE-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/whi5-SCE-Rep2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/whi5-cln3-SCE-Rep1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/tc2017/whi5-cln3-SCE-Rep2* $DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new data from 2018 \n",
    "#cp $AGGREGATE_DATA_DIR/asf1_glucose_1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_ethanol_1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_ethanol_1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_glucose_1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_ethanol_1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_glucose_1* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_glucose_2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_ethanol_2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_glucose_2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_ethanol_2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_ethanol_2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_glucose_2* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_ethanol_3* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_glucose_3* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_ethanol_3* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_glucose_3* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_glucose_3* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_ethanol_3* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_ethanol_4* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_glucose_4* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_glucose_4* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_glucose_4* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_ethanol_4* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_ethanol_4* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_glucose_5* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_glucose_5* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_glucose_5* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_ethanol_5* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_ethanol_5* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_ethanol_5* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_glucose_6* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_ethanol_6* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_ethanol_6* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/rtt109_glucose_6* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/WT_glucose_6* $DATA_DIR\n",
    "#cp $AGGREGATE_DATA_DIR/asf1_ethanol_6* $DATA_DIR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the analysis begin!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
