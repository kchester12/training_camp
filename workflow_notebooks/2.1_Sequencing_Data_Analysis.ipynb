{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequencing data analysis\n",
    "\n",
    "### IMPORTANT: Please make sure that your are using the bash kernel to run this notebook.\n",
    "#### (Do this at the beginning of every session) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook covers analysis of DNA sequencing data from raw files to processed signals.\n",
    "\n",
    "Although this analysis is for ATAC-seq data, many of the steps (especially the first section) are the same for other types of DNA sequencing experiments.\n",
    "\n",
    "We'll be doing the analysis in Bash, which is the standard language for UNIX command-line scripting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps in the analysis pipeline that are covered in this notebook are indicated below:\n",
    "![Sequencing Data Analysis 1](images/part1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting up the data\n",
    "\n",
    "We start with raw `.fastq.gz` files, which are provided by the sequencing instrument. For each DNA molecule (read) that was sequenced, they provide the nucleotide sequence, and information about the quality of the signal of that nucleotide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "### Set up variables storing the location of our data\n",
    "### The proper way to load your variables is with the ~/.bashrc command, but this is very slow in iPython \n",
    "export SUNETID=\"$(whoami)\"\n",
    "export WORK_DIR=\"/srv/scratch/training_camp/work/${SUNETID}\"\n",
    "export DATA_DIR=\"${WORK_DIR}/data\"\n",
    "[[ ! -d ${WORK_DIR}/data ]] && mkdir \"${WORK_DIR}/data\"\n",
    "export SRC_DIR=\"${WORK_DIR}/src\"\n",
    "[[ ! -d ${WORK_DIR}/src ]] && mkdir -p \"${WORK_DIR}/src\"\n",
    "export METADATA_DIR=\"/srv/scratch/training_camp/metadata\"\n",
    "export AGGREGATE_DATA_DIR=\"/srv/scratch/training_camp/data\"\n",
    "export AGGREGATE_ANALYSIS_DIR=\"/srv/scratch/training_camp/aggregate_analysis\"\n",
    "export YEAST_DIR=\"/srv/scratch/training_camp/saccer3\"\n",
    "export TMP=\"${WORK_DIR}/tmp\"\n",
    "export TEMP=$TMP\n",
    "export TMPDIR=$TMP\n",
    "[[ ! -d ${TMP} ]] && mkdir -p \"${TMP}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check exactly which fastqs we have (we copied these from $AGGREGATE_DATA_DIR to your personal $DATA_DIR in the last tutorial):\n",
    "\n",
    "(recall that the `ls` command lists the contents of a directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT-SCD-Rep1_R1_001.fastq.gz  WT-SCD-Rep2_R1_001.fastq.gz\r\n",
      "WT-SCD-Rep1_R2_001.fastq.gz  WT-SCD-Rep2_R2_001.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As a sanity check, we can also look at the size and last edited time of some of the fastqs by addind `-lrth` to the `ls` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 383M\r\n",
      "-rwxrwxr-x 1 ubuntu ubuntu  32M Sep  8 02:05 WT-SCD-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 ubuntu ubuntu  28M Sep  8 02:05 WT-SCD-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 ubuntu ubuntu 168M Sep  8 02:06 WT-SCD-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxr-x 1 ubuntu ubuntu 157M Sep  8 02:06 WT-SCD-Rep2_R2_001.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls -lrth $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the format of one of the fastqs. Notice that each read takes up 4 lines:\n",
    "1. the read name\n",
    "2. the read's nucleotide sequence\n",
    "3. a '+' to indicate the record contains another line\n",
    "4. a quality score for each base (a number encoded as a letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NS500418:691:HTFJ7AFXX:1:11101:13955:1071 1:N:0:CTCTCTAC+GCGATCTA\r\n",
      "TCTCTATGATGGTAATAGGCAAACATCGGGCGTACCTTAAAAGTCTTAGACATCACATAAACTGTCTCTTATACAC\r\n",
      "+\r\n",
      "AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEAEEEAEEEEEEEEE\r\n",
      "@NS500418:691:HTFJ7AFXX:1:11101:20718:1090 1:N:0:CTCTCTAC+GCGATCTA\r\n",
      "CCCCCTCCCATTACAAACTAAAATCTTACTTTTATTTTCTTTTGCCCTCTCTGTCGCCTGTCTCTTATACACATCT\r\n",
      "+\r\n",
      "AAAAAEEEEEEEEEEEEAEEEEEEEEEEAEEEEEEEEE<EEEEEEEEAE/EEEEE/EEEEAE<6EEEAEEEAEEAE\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "zcat $(ls $DATA_DIR/*gz | head -n 1) | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2:ATAC-seq data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ENCODE consortium (https://www.encodeproject.org/) uses a standard ATAC-seq data processing pipeline, which can be downloaded here: https://github.com/ENCODE-DCC/atac-seq-pipeline\n",
    "\n",
    "This pipeline is pre-installed on this computer and can be executed by running the **atac.bds** script. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#/opt/atac_dnase_pipelines/atac.bds --help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the pipeline is highly customizable and all the customizations might seem a bit confusing at first, do not worry -- for our purposes, the default settings will suffice. You will run the pipeline on your two experiments. Fill in the names of the FASTQ files corresponding to your two experiments below, as well as the name of the ouptut directory to store the processed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#You can find the experiment names in the file $METADATA_DIR/TC2018_samples.tsv.\n",
    "#Look under the column labeled \"ID\"\n",
    "#example: \n",
    "\n",
    "#export experiment1=\"WT_ethanol_1\"\n",
    "#export experiment2=\"asf1_ethanol_1\"\n",
    "\n",
    "export experiment1=\"WT-SCD-Rep1\"\n",
    "export experiment2=\"WT-SCD-Rep2\"\n",
    "\n",
    "#Create directories to store outputs from the pipeline\n",
    "#We will store the outputs in the $WORK_DIR\n",
    "export outdir1=$WORK_DIR/$experiment1\\_out \n",
    "export outdir2=$WORK_DIR/$experiment2\\_out\n",
    "mkdir $outdir1\n",
    "mkdir $outdir2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, kick off the pipeline! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bds_scr WT-SCD-Rep1 WT-SCD-Rep1.log atac.bds -out_dir /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep1_out -species saccer3 -fastq1_1 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep1\\_R1_001.fastq.gz -fastq1_2 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep1\\_R2_001.fastq.gz -nth 4\r\n",
      "[SCR_NAME] : WT-SCD-Rep1.BDS\r\n",
      "[HOST] : ip-172-31-26-41.us-west-1.compute.internal\r\n",
      "[LOG_FILE_NAME] : /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep1_out/log.txt\r\n",
      "[BDS_PARAM] :  /opt/atac_dnase_pipelines/atac.bds -out_dir /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep1_out -species saccer3 -fastq1_1 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep1_R1_001.fastq.gz -fastq1_2 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep1_R2_001.fastq.gz -nth 4\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#first experiment:\n",
    "echo \"bds_scr $experiment1 $experiment1.log atac.bds -out_dir $outdir1 -species saccer3 -fastq1_1 $DATA_DIR/$experiment1\\_R1_001.fastq.gz -fastq1_2 $DATA_DIR/$experiment1\\_R2_001.fastq.gz -nth 4\"\n",
    "bds_scr $experiment1 $outdir1/log.txt /opt/atac_dnase_pipelines/atac.bds -out_dir $outdir1 -species saccer3 -fastq1_1 $DATA_DIR/$experiment1\\_R1_001.fastq.gz -fastq1_2 $DATA_DIR/$experiment1\\_R2_001.fastq.gz -nth 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bds_scr WT-SCD-Rep2 WT-SCD-Rep2.log atac.bds -out_dir /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep2_out -species saccer3 -fastq1_1 /srv/scratch/training_camp/work/ubuntu/data/.fastq.gz -fastq1_2 /srv/scratch/training_camp/work/ubuntu/data/.fastq.gz -nth 4\r\n",
      "[SCR_NAME] : WT-SCD-Rep2.BDS\r\n",
      "[HOST] : ip-172-31-26-41.us-west-1.compute.internal\r\n",
      "[LOG_FILE_NAME] : /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep2_out/log.txt\r\n",
      "[BDS_PARAM] :  /opt/atac_dnase_pipelines/atac.bds -out_dir /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep2_out -species saccer3 -fastq1_1 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep2_R1_001.fastq.gz -fastq1_2 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep2_R2_001.fastq.gz -nth 4\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#second experiment:\n",
    "echo \"bds_scr $experiment2 $experiment2.log atac.bds -out_dir $outdir2 -species saccer3 -fastq1_1 $DATA_DIR/$experiment2_R1_001.fastq.gz -fastq1_2 $DATA_DIR/$experiment2_R2_001.fastq.gz -nth 4\"\n",
    "bds_scr $experiment2 $outdir2/log.txt /opt/atac_dnase_pipelines/atac.bds -out_dir $outdir2 -species saccer3 -fastq1_1 $DATA_DIR/$experiment2\\_R1_001.fastq.gz -fastq1_2 $DATA_DIR/$experiment2\\_R2_001.fastq.gz -nth 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline may run for an hour or so, so meanwhile, we will learn more about what it's doing under the hood. \n",
    "If you want to check on the progress, you can examine the latest entries in the  log file generated by the pipeline with teh *tail* command. The log files are specified by the [LOG_FILE_NAME] entry above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:09:05.526\tWait: Waiting for task to finish: atac.bds.20180908_052955_292/task.callpeak_macs2_atac.macs2_n_s_rep1_pr1.line_74.id_30, state: FINISHED\r\n",
      "00:09:05.526\tWait: Task 'atac.bds.20180908_052955_292/task.callpeak_macs2_atac.macs2_n_s_rep1_pr1.line_74.id_30' finished.\r\n",
      "00:09:05.526\tWait: Waiting for task to finish: atac.bds.20180908_052955_292/task.callpeak_idr.FRiP_rep1_pr.line_159.id_33, state: FINISHED\r\n",
      "00:09:05.526\tWait: Task 'atac.bds.20180908_052955_292/task.callpeak_idr.FRiP_rep1_pr.line_159.id_33' finished.\r\n",
      "00:09:05.526\tWaiting for all 'parrallel' to finish.\r\n",
      "00:09:05.526\tWaiting for parallel 'atac.bds.20180908_052955_292_parallel_29' to finish. RunState: FINISHED\r\n",
      "00:09:05.526\tWriting report file 'atac.bds.20180908_052955_292.report.html'\r\n",
      "00:09:05.556\tProgram 'atac.bds.20180908_052955_292' finished, exit value: 0, tasks executed: 26, tasks failed: 0, tasks failed names: .\r\n",
      "00:09:05.560\tFinished. Exit code: 0\r\n",
      "00:09:05.560\tExecutionerLocal 'Local[30]': Killed\r\n"
     ]
    }
   ],
   "source": [
    "tail $outdir1/log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:25:12.050\tWait: Waiting for task to finish: atac.bds.20180908_053005_965/task.callpeak_macs2_atac.macs2_n_s_rep1.line_74.id_29, state: FINISHED\r\n",
      "00:25:12.050\tWait: Task 'atac.bds.20180908_053005_965/task.callpeak_macs2_atac.macs2_n_s_rep1.line_74.id_29' finished.\r\n",
      "00:25:12.050\tWait: Waiting for task to finish: atac.bds.20180908_053005_965/task.graphviz.report.line_98.id_54, state: FINISHED\r\n",
      "00:25:12.050\tWait: Task 'atac.bds.20180908_053005_965/task.graphviz.report.line_98.id_54' finished.\r\n",
      "00:25:12.050\tWaiting for all 'parrallel' to finish.\r\n",
      "00:25:12.050\tWaiting for parallel 'atac.bds.20180908_053005_965_parallel_29' to finish. RunState: FINISHED\r\n",
      "00:25:12.050\tWriting report file 'atac.bds.20180908_053005_965.report.html'\r\n",
      "00:25:12.060\tProgram 'atac.bds.20180908_053005_965' finished, exit value: 0, tasks executed: 26, tasks failed: 0, tasks failed names: .\r\n",
      "00:25:12.060\tFinished. Exit code: 0\r\n",
      "00:25:12.060\tExecutionerLocal 'Local[30]': Killed\r\n"
     ]
    }
   ],
   "source": [
    "tail  $outdir2/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Examining the pipeline output\n",
    "\n",
    "The pipeline consists of multiple modules, with output files that include the following: \n",
    "\n",
    "```\n",
    "out                               # root dir. of outputs\n",
    "│\n",
    "├ *report.html                    #  HTML report\n",
    "├ *tracks.json                    #  Tracks datahub (JSON) for WashU browser\n",
    "├ ENCODE_summary.json             #  Metadata of all datafiles and QC results\n",
    "│\n",
    "├ align                           #  mapped alignments\n",
    "│ ├ rep1                          #   for true replicate 1 \n",
    "│ │ ├ *.trim.fastq.gz             #    adapter-trimmed fastq\n",
    "│ │ ├ *.bam                       #    raw bam\n",
    "│ │ ├ *.nodup.bam (E)             #    filtered and deduped bam\n",
    "│ │ ├ *.tagAlign.gz               #    tagAlign (bed6) generated from filtered bam\n",
    "│ │ ├ *.tn5.tagAlign.gz           #    TN5 shifted tagAlign for ATAC pipeline (not for DNase pipeline)\n",
    "│ │ └ *.*M.tagAlign.gz            #    subsampled tagAlign for cross-corr. analysis\n",
    "│ ├ rep2                          #   for true repilicate 2\n",
    "│ ...\n",
    "│ ├ pooled_rep                    #   for pooled replicate\n",
    "│ ├ pseudo_reps                   #   for self pseudo replicates\n",
    "│ │ ├ rep1                        #    for replicate 1\n",
    "│ │ │ ├ pr1                       #     for self pseudo replicate 1 of replicate 1\n",
    "│ │ │ ├ pr2                       #     for self pseudo replicate 2 of replicate 1\n",
    "│ │ ├ rep2                        #    for repilicate 2\n",
    "│ │ ...                           \n",
    "│ └ pooled_pseudo_reps            #   for pooled pseudo replicates\n",
    "│   ├ ppr1                        #    for pooled pseudo replicate 1 (rep1-pr1 + rep2-pr1 + ...)\n",
    "│   └ ppr2                        #    for pooled pseudo replicate 2 (rep1-pr2 + rep2-pr2 + ...)\n",
    "│\n",
    "├ peak                             #  peaks called\n",
    "│ └ macs2                          #   peaks generated by MACS2\n",
    "│   ├ rep1                         #    for replicate 1\n",
    "│   │ ├ *.narrowPeak.gz            #     narrowPeak (p-val threshold = 0.01)\n",
    "│   │ ├ *.filt.narrowPeak.gz (E)   #     blacklist filtered narrowPeak \n",
    "│   │ ├ *.narrowPeak.bb (E)        #     narrowPeak bigBed\n",
    "│   │ ├ *.narrowPeak.hammock.gz    #     narrowPeak track for WashU browser\n",
    "│   │ ├ *.pval0.1.narrowPeak.gz    #     narrowPeak (p-val threshold = 0.1)\n",
    "│   │ └ *.pval0.1.*K.narrowPeak.gz #     narrowPeak (p-val threshold = 0.1) with top *K peaks\n",
    "│   ├ rep2                         #    for replicate 2\n",
    "│   ...\n",
    "│   ├ pseudo_reps                          #   for self pseudo replicates\n",
    "│   ├ pooled_pseudo_reps                   #   for pooled pseudo replicates\n",
    "│   ├ overlap                              #   naive-overlapped peaks\n",
    "│   │ ├ *.naive_overlap.narrowPeak.gz      #     naive-overlapped peak\n",
    "│   │ └ *.naive_overlap.filt.narrowPeak.gz #     naive-overlapped peak after blacklist filtering\n",
    "│   └ idr                           #   IDR thresholded peaks\n",
    "│     ├ true_reps                   #    for replicate 1\n",
    "│     │ ├ *.narrowPeak.gz           #     IDR thresholded narrowPeak\n",
    "│     │ ├ *.filt.narrowPeak.gz (E)  #     IDR thresholded narrowPeak (blacklist filtered)\n",
    "│     │ └ *.12-col.bed.gz           #     IDR thresholded narrowPeak track for WashU browser\n",
    "│     ├ pseudo_reps                 #    for self pseudo replicates\n",
    "│     │ ├ rep1                      #    for replicate 1\n",
    "│     │ ...\n",
    "│     ├ optimal_set                 #    optimal IDR thresholded peaks\n",
    "│     │ └ *.filt.narrowPeak.gz (E)  #     IDR thresholded narrowPeak (blacklist filtered)\n",
    "│     ├ conservative_set            #    optimal IDR thresholded peaks\n",
    "│     │ └ *.filt.narrowPeak.gz (E)  #     IDR thresholded narrowPeak (blacklist filtered)\n",
    "│     ├ pseudo_reps                 #    for self pseudo replicates\n",
    "│     └ pooled_pseudo_reps          #    for pooled pseudo replicate\n",
    "│\n",
    "│   \n",
    "│ \n",
    "├ qc                              #  QC logs\n",
    "│ ├ *IDR_final.qc                 #   Final IDR QC\n",
    "│ ├ rep1                          #   for true replicate 1\n",
    "│ │ ├ *.align.log                 #    Bowtie2 mapping stat log\n",
    "│ │ ├ *.dup.qc                    #    Picard (or sambamba) MarkDuplicate QC log\n",
    "│ │ ├ *.pbc.qc                    #    PBC QC\n",
    "│ │ ├ *.nodup.flagstat.qc         #    Flagstat QC for filtered bam\n",
    "│ │ ├ *M.cc.qc                    #    Cross-correlation analysis score for tagAlign\n",
    "│ │ ├ *M.cc.plot.pdf/png          #    Cross-correlation analysis plot for tagAlign\n",
    "│ │ └ *_qc.html/txt               #    ATAQC report\n",
    "│ ...\n",
    "│\n",
    "├ signal                          #  signal tracks\n",
    "│ ├ macs2                         #   signal tracks generated by MACS2\n",
    "│ │ ├ rep1                        #    for true replicate 1 \n",
    "│ │ │ ├ *.pval.signal.bigwig (E)  #     signal track for p-val\n",
    "│ │ │ └ *.fc.signal.bigwig   (E)  #     signal track for fold change\n",
    "│ ...\n",
    "│ └ pooled_rep                    #   for pooled replicate\n",
    "│ \n",
    "├ report                          # files for HTML report\n",
    "└ meta                            # text files containing md5sum of output files and other metadata\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how well the reads aligned to the reference saccer3 genome. We'd like to see an overall alignment rate >=90% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601654 reads; of these:\r\n",
      "  601654 (100.00%) were paired; of these:\r\n",
      "    157957 (26.25%) aligned concordantly 0 times\r\n",
      "    275151 (45.73%) aligned concordantly exactly 1 time\r\n",
      "    168546 (28.01%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    157957 pairs aligned concordantly 0 times; of these:\r\n",
      "      60787 (38.48%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    97170 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      194340 mates make up the pairs; of these:\r\n",
      "        106902 (55.01%) aligned 0 times\r\n",
      "        948 (0.49%) aligned exactly 1 time\r\n",
      "        86490 (44.50%) aligned >1 times\r\n",
      "91.12% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "cat $outdir1/qc/rep1/*align.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3277012 reads; of these:\r\n",
      "  3277012 (100.00%) were paired; of these:\r\n",
      "    664721 (20.28%) aligned concordantly 0 times\r\n",
      "    1652322 (50.42%) aligned concordantly exactly 1 time\r\n",
      "    959969 (29.29%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    664721 pairs aligned concordantly 0 times; of these:\r\n",
      "      259947 (39.11%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    404774 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      809548 mates make up the pairs; of these:\r\n",
      "        350719 (43.32%) aligned 0 times\r\n",
      "        6069 (0.75%) aligned exactly 1 time\r\n",
      "        452760 (55.93%) aligned >1 times\r\n",
      "94.65% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "cat $outdir2/qc/rep1/*align.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine how many  peaks were called for each sample. We use the *zcat* command to examine the contents of a zipped file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520\r\n"
     ]
    }
   ],
   "source": [
    "zcat $outdir1/peak/macs2/overlap/optimal_set/*narrowPeak.gz | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641\r\n"
     ]
    }
   ],
   "source": [
    "zcat $outdir2/peak/macs2/overlap/optimal_set/*narrowPeak.gz | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Creating a merged peak set across all samples for downstream analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we merge the peaks across all conditions to create a master list of peaks for analysis. To do this, we concatenate the IDR peaks from all experiments, sort them, and merge them. \n",
    "\n",
    "We take the output of the processing pipeline from the $AGGREGATE_ANALYSIS directory. This is the same analysis you performed above, but gathered in one location for all experiments conducted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCD-Rep2_out/peak/macs2/overlap/optimal_set/WT-SCD-Rep2_out_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCD-Rep1_out/peak/macs2/overlap/optimal_set/WT-SCD-Rep1_out_rep1-pr.naive_overlap.narrowPeak.gz\r\n"
     ]
    }
   ],
   "source": [
    "cd $WORK_DIR\n",
    "#Use the \"find\" command to identify all IDR narrowPeak output files and write them to a file. \n",
    "find $AGGREGATE_ANALYSIS_DIR  -wholename \"*peak/macs2/overlap/optimal_set/*narrowPeak.gz\" > narrowPeak_files.txt\n",
    "\n",
    "#sanity check the file \n",
    "head narrowPeak_files.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrI\t108652\t109044\tPeak_3176\t94\t.\t2.16203\t9.42043\t8.13851\t129\r\n",
      "chrI\t108652\t109044\tPeak_4811\t22\t.\t1.43200\t2.27093\t1.31249\t377\r\n",
      "chrI\t113337\t114374\tPeak_1054\t369\t.\t3.76250\t36.94333\t35.13755\t145\r\n",
      "chrI\t113337\t114374\tPeak_3483\t73\t.\t1.99356\t7.39529\t6.17374\t708\r\n",
      "chrI\t113337\t114374\tPeak_3694\t61\t.\t1.88125\t6.16174\t4.98351\t411\r\n",
      "chrI\t114606\t114837\tPeak_1041\t375\t.\t3.79058\t37.53549\t35.72075\t111\r\n",
      "chrI\t129068\t129274\tPeak_2465\t148\t.\t2.55513\t14.88796\t13.47084\t84\r\n",
      "chrI\t130158\t130752\tPeak_3177\t94\t.\t2.16203\t9.42043\t8.13851\t228\r\n",
      "chrI\t130158\t130752\tPeak_3281\t87\t.\t2.10588\t8.72283\t7.46047\t424\r\n",
      "chrI\t138986\t139388\tPeak_1672\t241\t.\t3.01769\t24.11693\t22.52225\t239\r\n"
     ]
    }
   ],
   "source": [
    "#Now, iterate through the list of narrowPeak files and concatenate them into a single master peak list. \n",
    "for f in `cat narrowPeak_files.txt`\n",
    "do \n",
    "    zcat $f >> all.peaks.bed\n",
    "done\n",
    "\n",
    "#sanity check the all.peaks.bed file \n",
    "head all.peaks.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrI\t77\t637\tPeak_3179\t94\t.\t2.16203\t9.42043\t8.13851\t101\r\n",
      "chrI\t77\t637\tPeak_2111\t184\t.\t2.77976\t18.43291\t16.94266\t416\r\n",
      "chrI\t125\t573\tPeak_2324\t33\t.\t2.35166\t3.32030\t1.93039\t164\r\n",
      "chrI\t125\t573\tPeak_2148\t38\t.\t2.50844\t3.80537\t2.35601\t362\r\n",
      "chrI\t20678\t21197\tPeak_2417\t153\t.\t2.58321\t15.31523\t13.88857\t387\r\n",
      "chrI\t20678\t21197\tPeak_4276\t37\t.\t1.62855\t3.75592\t2.68746\t72\r\n",
      "chrI\t28377\t28921\tPeak_1113\t351\t.\t3.67827\t35.18621\t33.40816\t323\r\n",
      "chrI\t28398\t28927\tPeak_647\t112\t.\t4.38977\t11.27319\t9.23240\t292\r\n",
      "chrI\t29730\t30101\tPeak_1052\t370\t.\t3.55305\t37.05812\t35.25110\t208\r\n",
      "chrI\t32573\t33282\tPeak_452\t626\t.\t4.28082\t62.61963\t60.38811\t478\r\n"
     ]
    }
   ],
   "source": [
    "#sort the concatenated file \n",
    "bedtools sort -i all.peaks.bed > all.peaks.sorted.bed \n",
    "\n",
    "head all.peaks.sorted.bed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrI\t77\t637\r\n",
      "chrI\t20678\t21197\r\n",
      "chrI\t28377\t28927\r\n",
      "chrI\t29730\t30101\r\n",
      "chrI\t32573\t33282\r\n",
      "chrI\t34225\t35046\r\n",
      "chrI\t45220\t45746\r\n",
      "chrI\t48290\t48723\r\n",
      "chrI\t58123\t58848\r\n",
      "chrI\t61040\t61459\r\n"
     ]
    }
   ],
   "source": [
    "#merge the sorted, concatenated fileto join overlapping peaks \n",
    "bedtools merge -i all.peaks.sorted.bed > all_merged.peaks.bed \n",
    "\n",
    "head all_merged.peaks.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#zip the merged peak file to save space \n",
    "gzip -f all_merged.peaks.bed "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
