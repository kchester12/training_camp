{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequencing data analysis\n",
    "\n",
    "### IMPORTANT: Please make sure that your are using the bash kernel to run this notebook.\n",
    "#### (Do this at the beginning of every session) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook covers analysis of DNA sequencing data from raw files to processed signals.\n",
    "\n",
    "Although this analysis is for ATAC-seq data, many of the steps (especially the first section) are the same for other types of DNA sequencing experiments.\n",
    "\n",
    "We'll be doing the analysis in Bash, which is the standard language for UNIX command-line scripting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps in the analysis pipeline that are covered in this notebook are indicated below:\n",
    "![Sequencing Data Analysis 1](images/part1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting up the data\n",
    "\n",
    "We start with raw `.fastq.gz` files, which are provided by the sequencing instrument. For each DNA molecule (read) that was sequenced, they provide the nucleotide sequence, and information about the quality of the signal of that nucleotide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "### Set up variables storing the location of our data\n",
    "### The proper way to load your variables is with the ~/.bashrc command, but this is very slow in iPython \n",
    "export SUNETID=\"$(whoami)\"\n",
    "export WORK_DIR=\"/srv/scratch/training_camp/work/${SUNETID}\"\n",
    "export DATA_DIR=\"${WORK_DIR}/data\"\n",
    "[[ ! -d ${WORK_DIR}/data ]] && mkdir \"${WORK_DIR}/data\"\n",
    "export SRC_DIR=\"${WORK_DIR}/src\"\n",
    "[[ ! -d ${WORK_DIR}/src ]] && mkdir -p \"${WORK_DIR}/src\"\n",
    "export METADATA_DIR=\"/srv/scratch/training_camp/metadata\"\n",
    "export AGGREGATE_DATA_DIR=\"/srv/scratch/training_camp/data\"\n",
    "export AGGREGATE_ANALYSIS_DIR=\"/srv/scratch/training_camp/aggregate_analysis\"\n",
    "export YEAST_DIR=\"/srv/scratch/training_camp/saccer3\"\n",
    "export TMP=\"${WORK_DIR}/tmp\"\n",
    "export TEMP=$TMP\n",
    "export TMPDIR=$TMP\n",
    "[[ ! -d ${TMP} ]] && mkdir -p \"${TMP}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check exactly which fastqs we have (we copied these from \\$AGGREGATE_DATA_DIR to your personal $DATA_DIR in the last tutorial):\n",
    "\n",
    "(recall that the `ls` command lists the contents of a directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atac.bds.20180908_171658_871.dag.js\t  cln3-SCE-Rep2_R2_001.fastq.gz\r\n",
      "atac.bds.20180908_171658_871.report.html  run.sh\r\n",
      "atac.bds.20180908_172210_278.dag.js\t  run.sh~\r\n",
      "atac.bds.20180908_172210_278.report.html  whi5-cln3-SCE-Rep1_R1_001.fastq.gz\r\n",
      "atac.bds.20180908_173819_316.dag.js\t  whi5-cln3-SCE-Rep1_R2_001.fastq.gz\r\n",
      "atac.bds.20180908_173819_316.report.html  whi5-cln3-SCE-Rep2_R1_001.fastq.gz\r\n",
      "atac.bds.20180908_174431_590.dag.js\t  whi5-cln3-SCE-Rep2_R2_001.fastq.gz\r\n",
      "atac.bds.20180908_174431_590.report.html  whi5-SCE-Rep1_R1_001.fastq.gz\r\n",
      "atac.bds.20180908_183721_333.dag.js\t  whi5-SCE-Rep1_R2_001.fastq.gz\r\n",
      "atac.bds.20180908_183721_333.report.html  whi5-SCE-Rep2_R1_001.fastq.gz\r\n",
      "atac.bds.20180908_183721_438.dag.js\t  whi5-SCE-Rep2_R2_001.fastq.gz\r\n",
      "atac.bds.20180908_183721_438.report.html  WT-SCD-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n",
      "cln3-SCD-0_6MNaCl-Rep1_R1_001.fastq.gz\t  WT-SCD-0_6MNaCl-Rep1_R2_001.fastq.gz\r\n",
      "cln3-SCD-0_6MNaCl-Rep1_R2_001.fastq.gz\t  WT-SCD-0_6MNaCl-Rep2_R1_001.fastq.gz\r\n",
      "cln3-SCD-0_6MNaCl-Rep2_R1_001.fastq.gz\t  WT-SCD-0_6MNaCl-Rep2_R2_001.fastq.gz\r\n",
      "cln3-SCD-0_6MNaCl-Rep2_R2_001.fastq.gz\t  WT-SCD-Rep1_R1_001.fastq.gz\r\n",
      "cln3-SCD-Rep1_R1_001.fastq.gz\t\t  WT-SCD-Rep1_R2_001.fastq.gz\r\n",
      "cln3-SCD-Rep1_R2_001.fastq.gz\t\t  WT-SCD-Rep2_R1_001.fastq.gz\r\n",
      "cln3-SCD-Rep2_R1_001.fastq.gz\t\t  WT-SCD-Rep2_R2_001.fastq.gz\r\n",
      "cln3-SCD-Rep2_R2_001.fastq.gz\t\t  WT-SCE-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n",
      "cln3-SCE-0_6MNaCl-Rep1_R1_001.fastq.gz\t  WT-SCE-0_6MNaCl-Rep1_R2_001.fastq.gz\r\n",
      "cln3-SCE-0_6MNaCl-Rep1_R2_001.fastq.gz\t  WT-SCE-0_6MNaCl-Rep2_R1_001.fastq.gz\r\n",
      "cln3-SCE-0_6MNaCl-Rep2_R1_001.fastq.gz\t  WT-SCE-0_6MNaCl-Rep2_R2_001.fastq.gz\r\n",
      "cln3-SCE-0_6MNaCl-Rep2_R2_001.fastq.gz\t  WT-SCE-Rep1_R1_001.fastq.gz\r\n",
      "cln3-SCE-Rep1_R1_001.fastq.gz\t\t  WT-SCE-Rep1_R2_001.fastq.gz\r\n",
      "cln3-SCE-Rep1_R2_001.fastq.gz\t\t  WT-SCE-Rep2_R1_001.fastq.gz\r\n",
      "cln3-SCE-Rep2_R1_001.fastq.gz\t\t  WT-SCE-Rep2_R2_001.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As a sanity check, we can also look at the size and last edited time of some of the fastqs by addind `-lrth` to the `ls` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.4G\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  81M Sep  8 17:03 WT-SCD-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  73M Sep  8 17:04 WT-SCD-0_6MNaCl-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 159M Sep  8 17:04 WT-SCD-0_6MNaCl-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 150M Sep  8 17:04 WT-SCD-0_6MNaCl-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  32M Sep  8 17:04 WT-SCD-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  28M Sep  8 17:04 WT-SCD-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 168M Sep  8 17:04 WT-SCD-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 157M Sep  8 17:04 WT-SCD-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 203M Sep  8 17:04 WT-SCE-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 183M Sep  8 17:04 WT-SCE-0_6MNaCl-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 212M Sep  8 17:04 WT-SCE-0_6MNaCl-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 199M Sep  8 17:04 WT-SCE-0_6MNaCl-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 9.7M Sep  8 17:04 WT-SCE-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 8.5M Sep  8 17:04 WT-SCE-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 207M Sep  8 17:04 WT-SCE-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 194M Sep  8 17:04 WT-SCE-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  84K Sep  8 17:04 cln3-SCD-0_6MNaCl-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  98K Sep  8 17:04 cln3-SCD-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  43K Sep  8 17:04 cln3-SCD-0_6MNaCl-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  49K Sep  8 17:04 cln3-SCD-0_6MNaCl-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 133M Sep  8 17:04 cln3-SCD-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 122M Sep  8 17:04 cln3-SCD-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 164M Sep  8 17:04 cln3-SCD-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 153M Sep  8 17:04 cln3-SCD-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 199M Sep  8 17:04 cln3-SCE-0_6MNaCl-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 179M Sep  8 17:04 cln3-SCE-0_6MNaCl-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 156M Sep  8 17:04 cln3-SCE-0_6MNaCl-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 147M Sep  8 17:04 cln3-SCE-0_6MNaCl-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 192M Sep  8 17:04 cln3-SCE-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 176M Sep  8 17:04 cln3-SCE-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  90M Sep  8 17:04 cln3-SCE-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  86M Sep  8 17:04 cln3-SCE-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 193M Sep  8 17:04 whi5-SCE-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 175M Sep  8 17:04 whi5-SCE-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 209M Sep  8 17:04 whi5-SCE-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 193M Sep  8 17:04 whi5-SCE-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 247M Sep  8 17:04 whi5-cln3-SCE-Rep1_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 232M Sep  8 17:04 whi5-cln3-SCE-Rep1_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 224M Sep  8 17:04 whi5-cln3-SCE-Rep2_R1_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 211M Sep  8 17:05 whi5-cln3-SCE-Rep2_R2_001.fastq.gz\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu  62K Sep  8 17:18 atac.bds.20180908_171658_871.report.html\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 2.1K Sep  8 17:18 atac.bds.20180908_171658_871.dag.js\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 130K Sep  8 17:35 atac.bds.20180908_172210_278.report.html\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 2.9K Sep  8 17:35 atac.bds.20180908_172210_278.dag.js\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  62K Sep  8 17:39 atac.bds.20180908_173819_316.report.html\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 2.1K Sep  8 17:39 atac.bds.20180908_173819_316.dag.js\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 1.1K Sep  8 17:44 run.sh~\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 134K Sep  8 18:16 atac.bds.20180908_174431_590.report.html\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 2.9K Sep  8 18:16 atac.bds.20180908_174431_590.dag.js\r\n",
      "-rwxrwxrwx 1 ubuntu ubuntu 1021 Sep  8 18:37 run.sh\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 130K Sep  8 19:07 atac.bds.20180908_183721_438.report.html\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 2.9K Sep  8 19:07 atac.bds.20180908_183721_438.dag.js\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 134K Sep  8 19:20 atac.bds.20180908_183721_333.report.html\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 2.9K Sep  8 19:20 atac.bds.20180908_183721_333.dag.js\r\n"
     ]
    }
   ],
   "source": [
    "ls -lrth $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the format of one of the fastqs. Notice that each read takes up 4 lines:\n",
    "1. the read name\n",
    "2. the read's nucleotide sequence\n",
    "3. a '+' to indicate the record contains another line\n",
    "4. a quality score for each base (a number encoded as a letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NS500418:691:HTFJ7AFXX:1:11101:13781:5936 1:N:0:CGAGGCTG+GCGATCTA\r\n",
      "CTTATACACATCTCCGAGCCCACGAGACCGAGGCTGATCTCGTATGCCGTCTTCTGCTGGAAAAAAAAAAGGGGGG\r\n",
      "+\r\n",
      "AAAAAAEAEEEEEAEE//EEEEEE/EEEEE/EEEEE6E</EA/EEEEEEE/AEAEE<E/E/EEEE6E6///EEEEE\r\n",
      "@NS500418:691:HTFJ7AFXX:1:11101:23098:6041 1:N:0:CGAGGCTG+GCGATCTA\r\n",
      "CCCAGATATTGGGCGACAGCCAGGTTTTCAGCCAGACGACAGGCGAACTTTTGTTGACCTCAACGCGCACCTCCGT\r\n",
      "+\r\n",
      "AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEAEEEEEEAAEEEEEEEEEAEEEEEEEEEEEEEAEEEAA\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "zcat $(ls $DATA_DIR/*gz | head -n 1) | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2:ATAC-seq data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ENCODE consortium (https://www.encodeproject.org/) uses a standard ATAC-seq data processing pipeline, which can be downloaded here: https://github.com/ENCODE-DCC/atac-seq-pipeline\n",
    "\n",
    "This pipeline is pre-installed on this computer and can be executed by running the **atac.bds** script. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#/opt/atac_dnase_pipelines/atac.bds --help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the pipeline is highly customizable and all the customizations might seem a bit confusing at first, do not worry -- for our purposes, the default settings will suffice. You will run the pipeline on your two experiments. Fill in the names of the FASTQ files corresponding to your two experiments below, as well as the name of the ouptut directory to store the processed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep1_out’: File exists\r\n",
      "mkdir: cannot create directory ‘/srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep2_out’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "#You can find the experiment names in the file $METADATA_DIR/TC2018_samples.tsv.\n",
    "#Look under the column labeled \"ID\"\n",
    "#example: \n",
    "\n",
    "#export experiment1=\"WT_ethanol_1\"\n",
    "#export experiment2=\"asf1_ethanol_1\"\n",
    "\n",
    "export experiment1=\"WT-SCD-Rep1\"\n",
    "export experiment2=\"WT-SCD-Rep2\"\n",
    "\n",
    "#Create directories to store outputs from the pipeline\n",
    "#We will store the outputs in the $WORK_DIR\n",
    "export outdir1=$WORK_DIR/$experiment1\\_out \n",
    "export outdir2=$WORK_DIR/$experiment2\\_out\n",
    "mkdir $outdir1\n",
    "mkdir $outdir2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, kick off the pipeline! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bds_scr WT-SCD-Rep1 WT-SCD-Rep1.log atac.bds -out_dir /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep1_out -species saccer3 -fastq1_1 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep1\\_R1_001.fastq.gz -fastq1_2 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep1\\_R2_001.fastq.gz -nth 4\r\n",
      "[SCR_NAME] : WT-SCD-Rep1.BDS\r\n",
      "[HOST] : ip-172-31-26-41.us-west-1.compute.internal\r\n",
      "[LOG_FILE_NAME] : /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep1_out/log.txt\r\n",
      "[BDS_PARAM] :  /opt/atac_dnase_pipelines/atac.bds -out_dir /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep1_out -species saccer3 -fastq1_1 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep1_R1_001.fastq.gz -fastq1_2 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep1_R2_001.fastq.gz -nth 4\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#first experiment:\n",
    "echo \"bds_scr $experiment1 $experiment1.log atac.bds -out_dir $outdir1 -species saccer3 -fastq1_1 $DATA_DIR/$experiment1\\_R1_001.fastq.gz -fastq1_2 $DATA_DIR/$experiment1\\_R2_001.fastq.gz -nth 4\"\n",
    "bds_scr $experiment1 $outdir1/log.txt /opt/atac_dnase_pipelines/atac.bds -out_dir $outdir1 -species saccer3 -fastq1_1 $DATA_DIR/$experiment1\\_R1_001.fastq.gz -fastq1_2 $DATA_DIR/$experiment1\\_R2_001.fastq.gz -nth 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bds_scr WT-SCD-Rep2 WT-SCD-Rep2.log atac.bds -out_dir /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep2_out -species saccer3 -fastq1_1 /srv/scratch/training_camp/work/ubuntu/data/.fastq.gz -fastq1_2 /srv/scratch/training_camp/work/ubuntu/data/.fastq.gz -nth 4\r\n",
      "[SCR_NAME] : WT-SCD-Rep2.BDS\r\n",
      "[HOST] : ip-172-31-26-41.us-west-1.compute.internal\r\n",
      "[LOG_FILE_NAME] : /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep2_out/log.txt\r\n",
      "[BDS_PARAM] :  /opt/atac_dnase_pipelines/atac.bds -out_dir /srv/scratch/training_camp/work/ubuntu/WT-SCD-Rep2_out -species saccer3 -fastq1_1 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep2_R1_001.fastq.gz -fastq1_2 /srv/scratch/training_camp/work/ubuntu/data/WT-SCD-Rep2_R2_001.fastq.gz -nth 4\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#second experiment:\n",
    "echo \"bds_scr $experiment2 $experiment2.log atac.bds -out_dir $outdir2 -species saccer3 -fastq1_1 $DATA_DIR/$experiment2_R1_001.fastq.gz -fastq1_2 $DATA_DIR/$experiment2_R2_001.fastq.gz -nth 4\"\n",
    "bds_scr $experiment2 $outdir2/log.txt /opt/atac_dnase_pipelines/atac.bds -out_dir $outdir2 -species saccer3 -fastq1_1 $DATA_DIR/$experiment2\\_R1_001.fastq.gz -fastq1_2 $DATA_DIR/$experiment2\\_R2_001.fastq.gz -nth 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline may run for an hour or so, so meanwhile, we will learn more about what it's doing under the hood. \n",
    "If you want to check on the progress, you can examine the latest entries in the  log file generated by the pipeline with teh *tail* command. The log files are specified by the [LOG_FILE_NAME] entry above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:09:05.526\tWait: Waiting for task to finish: atac.bds.20180908_052955_292/task.callpeak_macs2_atac.macs2_n_s_rep1_pr1.line_74.id_30, state: FINISHED\r\n",
      "00:09:05.526\tWait: Task 'atac.bds.20180908_052955_292/task.callpeak_macs2_atac.macs2_n_s_rep1_pr1.line_74.id_30' finished.\r\n",
      "00:09:05.526\tWait: Waiting for task to finish: atac.bds.20180908_052955_292/task.callpeak_idr.FRiP_rep1_pr.line_159.id_33, state: FINISHED\r\n",
      "00:09:05.526\tWait: Task 'atac.bds.20180908_052955_292/task.callpeak_idr.FRiP_rep1_pr.line_159.id_33' finished.\r\n",
      "00:09:05.526\tWaiting for all 'parrallel' to finish.\r\n",
      "00:09:05.526\tWaiting for parallel 'atac.bds.20180908_052955_292_parallel_29' to finish. RunState: FINISHED\r\n",
      "00:09:05.526\tWriting report file 'atac.bds.20180908_052955_292.report.html'\r\n",
      "00:09:05.556\tProgram 'atac.bds.20180908_052955_292' finished, exit value: 0, tasks executed: 26, tasks failed: 0, tasks failed names: .\r\n",
      "00:09:05.560\tFinished. Exit code: 0\r\n",
      "00:09:05.560\tExecutionerLocal 'Local[30]': Killed\r\n"
     ]
    }
   ],
   "source": [
    "tail $outdir1/log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:25:12.050\tWait: Waiting for task to finish: atac.bds.20180908_053005_965/task.callpeak_macs2_atac.macs2_n_s_rep1.line_74.id_29, state: FINISHED\r\n",
      "00:25:12.050\tWait: Task 'atac.bds.20180908_053005_965/task.callpeak_macs2_atac.macs2_n_s_rep1.line_74.id_29' finished.\r\n",
      "00:25:12.050\tWait: Waiting for task to finish: atac.bds.20180908_053005_965/task.graphviz.report.line_98.id_54, state: FINISHED\r\n",
      "00:25:12.050\tWait: Task 'atac.bds.20180908_053005_965/task.graphviz.report.line_98.id_54' finished.\r\n",
      "00:25:12.050\tWaiting for all 'parrallel' to finish.\r\n",
      "00:25:12.050\tWaiting for parallel 'atac.bds.20180908_053005_965_parallel_29' to finish. RunState: FINISHED\r\n",
      "00:25:12.050\tWriting report file 'atac.bds.20180908_053005_965.report.html'\r\n",
      "00:25:12.060\tProgram 'atac.bds.20180908_053005_965' finished, exit value: 0, tasks executed: 26, tasks failed: 0, tasks failed names: .\r\n",
      "00:25:12.060\tFinished. Exit code: 0\r\n",
      "00:25:12.060\tExecutionerLocal 'Local[30]': Killed\r\n"
     ]
    }
   ],
   "source": [
    "tail  $outdir2/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Examining the pipeline output\n",
    "\n",
    "The pipeline consists of multiple modules, with output files that include the following: \n",
    "\n",
    "```\n",
    "out                               # root dir. of outputs\n",
    "│\n",
    "├ *report.html                    #  HTML report\n",
    "├ *tracks.json                    #  Tracks datahub (JSON) for WashU browser\n",
    "├ ENCODE_summary.json             #  Metadata of all datafiles and QC results\n",
    "│\n",
    "├ align                           #  mapped alignments\n",
    "│ ├ rep1                          #   for true replicate 1 \n",
    "│ │ ├ *.trim.fastq.gz             #    adapter-trimmed fastq\n",
    "│ │ ├ *.bam                       #    raw bam\n",
    "│ │ ├ *.nodup.bam (E)             #    filtered and deduped bam\n",
    "│ │ ├ *.tagAlign.gz               #    tagAlign (bed6) generated from filtered bam\n",
    "│ │ ├ *.tn5.tagAlign.gz           #    TN5 shifted tagAlign for ATAC pipeline (not for DNase pipeline)\n",
    "│ │ └ *.*M.tagAlign.gz            #    subsampled tagAlign for cross-corr. analysis\n",
    "│ ├ rep2                          #   for true repilicate 2\n",
    "│ ...\n",
    "│ ├ pooled_rep                    #   for pooled replicate\n",
    "│ ├ pseudo_reps                   #   for self pseudo replicates\n",
    "│ │ ├ rep1                        #    for replicate 1\n",
    "│ │ │ ├ pr1                       #     for self pseudo replicate 1 of replicate 1\n",
    "│ │ │ ├ pr2                       #     for self pseudo replicate 2 of replicate 1\n",
    "│ │ ├ rep2                        #    for repilicate 2\n",
    "│ │ ...                           \n",
    "│ └ pooled_pseudo_reps            #   for pooled pseudo replicates\n",
    "│   ├ ppr1                        #    for pooled pseudo replicate 1 (rep1-pr1 + rep2-pr1 + ...)\n",
    "│   └ ppr2                        #    for pooled pseudo replicate 2 (rep1-pr2 + rep2-pr2 + ...)\n",
    "│\n",
    "├ peak                             #  peaks called\n",
    "│ └ macs2                          #   peaks generated by MACS2\n",
    "│   ├ rep1                         #    for replicate 1\n",
    "│   │ ├ *.narrowPeak.gz            #     narrowPeak (p-val threshold = 0.01)\n",
    "│   │ ├ *.filt.narrowPeak.gz (E)   #     blacklist filtered narrowPeak \n",
    "│   │ ├ *.narrowPeak.bb (E)        #     narrowPeak bigBed\n",
    "│   │ ├ *.narrowPeak.hammock.gz    #     narrowPeak track for WashU browser\n",
    "│   │ ├ *.pval0.1.narrowPeak.gz    #     narrowPeak (p-val threshold = 0.1)\n",
    "│   │ └ *.pval0.1.*K.narrowPeak.gz #     narrowPeak (p-val threshold = 0.1) with top *K peaks\n",
    "│   ├ rep2                         #    for replicate 2\n",
    "│   ...\n",
    "│   ├ pseudo_reps                          #   for self pseudo replicates\n",
    "│   ├ pooled_pseudo_reps                   #   for pooled pseudo replicates\n",
    "│   ├ overlap                              #   naive-overlapped peaks\n",
    "│   │ ├ *.naive_overlap.narrowPeak.gz      #     naive-overlapped peak\n",
    "│   │ └ *.naive_overlap.filt.narrowPeak.gz #     naive-overlapped peak after blacklist filtering\n",
    "│   └ idr                           #   IDR thresholded peaks\n",
    "│     ├ true_reps                   #    for replicate 1\n",
    "│     │ ├ *.narrowPeak.gz           #     IDR thresholded narrowPeak\n",
    "│     │ ├ *.filt.narrowPeak.gz (E)  #     IDR thresholded narrowPeak (blacklist filtered)\n",
    "│     │ └ *.12-col.bed.gz           #     IDR thresholded narrowPeak track for WashU browser\n",
    "│     ├ pseudo_reps                 #    for self pseudo replicates\n",
    "│     │ ├ rep1                      #    for replicate 1\n",
    "│     │ ...\n",
    "│     ├ optimal_set                 #    optimal IDR thresholded peaks\n",
    "│     │ └ *.filt.narrowPeak.gz (E)  #     IDR thresholded narrowPeak (blacklist filtered)\n",
    "│     ├ conservative_set            #    optimal IDR thresholded peaks\n",
    "│     │ └ *.filt.narrowPeak.gz (E)  #     IDR thresholded narrowPeak (blacklist filtered)\n",
    "│     ├ pseudo_reps                 #    for self pseudo replicates\n",
    "│     └ pooled_pseudo_reps          #    for pooled pseudo replicate\n",
    "│\n",
    "│   \n",
    "│ \n",
    "├ qc                              #  QC logs\n",
    "│ ├ *IDR_final.qc                 #   Final IDR QC\n",
    "│ ├ rep1                          #   for true replicate 1\n",
    "│ │ ├ *.align.log                 #    Bowtie2 mapping stat log\n",
    "│ │ ├ *.dup.qc                    #    Picard (or sambamba) MarkDuplicate QC log\n",
    "│ │ ├ *.pbc.qc                    #    PBC QC\n",
    "│ │ ├ *.nodup.flagstat.qc         #    Flagstat QC for filtered bam\n",
    "│ │ ├ *M.cc.qc                    #    Cross-correlation analysis score for tagAlign\n",
    "│ │ ├ *M.cc.plot.pdf/png          #    Cross-correlation analysis plot for tagAlign\n",
    "│ │ └ *_qc.html/txt               #    ATAQC report\n",
    "│ ...\n",
    "│\n",
    "├ signal                          #  signal tracks\n",
    "│ ├ macs2                         #   signal tracks generated by MACS2\n",
    "│ │ ├ rep1                        #    for true replicate 1 \n",
    "│ │ │ ├ *.pval.signal.bigwig (E)  #     signal track for p-val\n",
    "│ │ │ └ *.fc.signal.bigwig   (E)  #     signal track for fold change\n",
    "│ ...\n",
    "│ └ pooled_rep                    #   for pooled replicate\n",
    "│ \n",
    "├ report                          # files for HTML report\n",
    "└ meta                            # text files containing md5sum of output files and other metadata\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how well the reads aligned to the reference saccer3 genome. We'd like to see an overall alignment rate >=90% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601654 reads; of these:\r\n",
      "  601654 (100.00%) were paired; of these:\r\n",
      "    157957 (26.25%) aligned concordantly 0 times\r\n",
      "    275151 (45.73%) aligned concordantly exactly 1 time\r\n",
      "    168546 (28.01%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    157957 pairs aligned concordantly 0 times; of these:\r\n",
      "      60787 (38.48%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    97170 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      194340 mates make up the pairs; of these:\r\n",
      "        106902 (55.01%) aligned 0 times\r\n",
      "        948 (0.49%) aligned exactly 1 time\r\n",
      "        86490 (44.50%) aligned >1 times\r\n",
      "91.12% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "cat $outdir1/qc/rep1/*align.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3277012 reads; of these:\r\n",
      "  3277012 (100.00%) were paired; of these:\r\n",
      "    664721 (20.28%) aligned concordantly 0 times\r\n",
      "    1652322 (50.42%) aligned concordantly exactly 1 time\r\n",
      "    959969 (29.29%) aligned concordantly >1 times\r\n",
      "    ----\r\n",
      "    664721 pairs aligned concordantly 0 times; of these:\r\n",
      "      259947 (39.11%) aligned discordantly 1 time\r\n",
      "    ----\r\n",
      "    404774 pairs aligned 0 times concordantly or discordantly; of these:\r\n",
      "      809548 mates make up the pairs; of these:\r\n",
      "        350719 (43.32%) aligned 0 times\r\n",
      "        6069 (0.75%) aligned exactly 1 time\r\n",
      "        452760 (55.93%) aligned >1 times\r\n",
      "94.65% overall alignment rate\r\n"
     ]
    }
   ],
   "source": [
    "cat $outdir2/qc/rep1/*align.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine how many  peaks were called for each sample. We use the *zcat* command to examine the contents of a zipped file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520\r\n"
     ]
    }
   ],
   "source": [
    "zcat $outdir1/peak/macs2/overlap/optimal_set/*narrowPeak.gz | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641\r\n"
     ]
    }
   ],
   "source": [
    "zcat $outdir2/peak/macs2/overlap/optimal_set/*narrowPeak.gz | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Creating a merged peak set across all samples for downstream analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we merge the peaks across all conditions to create a master list of peaks for analysis. To do this, we concatenate the IDR peaks from all experiments, sort them, and merge them. \n",
    "\n",
    "We take the output of the processing pipeline from the $AGGREGATE_ANALYSIS directory. This is the same analysis you performed above, but gathered in one location for all experiments conducted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cd $WORK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/scratch/training_camp/aggregate_analysis/whi5-SCE-Rep1/peak/macs2/overlap/optimal_set/whi5-SCE-Rep1_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCD-Rep2_out/peak/macs2/overlap/optimal_set/WT-SCD-Rep2_out_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCD-Rep2/peak/macs2/overlap/optimal_set/cln3-SCD-Rep2_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCE-Rep2/peak/macs2/overlap/optimal_set/cln3-SCE-Rep2_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/whi5-cln3-SCE-Rep2/peak/macs2/overlap/optimal_set/whi5-cln3-SCE-Rep2_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCE-0_6MNaCl-Rep1/peak/macs2/overlap/optimal_set/WT-SCE-0_6MNaCl-Rep1_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCD-Rep1/peak/macs2/overlap/optimal_set/cln3-SCD-Rep1_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCD-0_6MNaCl-Rep2/peak/macs2/overlap/optimal_set/WT-SCD-0_6MNaCl-Rep2_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCE-0_6MNaCl-Rep2/peak/macs2/overlap/optimal_set/cln3-SCE-0_6MNaCl-Rep2_rep1-pr.naive_overlap.narrowPeak.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCE-Rep2/peak/macs2/overlap/optimal_set/WT-SCE-Rep2_rep1-pr.naive_overlap.narrowPeak.gz\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Use the \"find\" command to identify all IDR narrowPeak output files and write them to a file. \n",
    "find $AGGREGATE_ANALYSIS_DIR  -wholename \"*peak/macs2/overlap/optimal_set/*narrowPeak.gz\" > narrowPeak_files.txt\n",
    "\n",
    "#sanity check the file \n",
    "head narrowPeak_files.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrI\t108652\t109044\tPeak_3176\t94\t.\t2.16203\t9.42043\t8.13851\t129\r\n",
      "chrI\t108652\t109044\tPeak_4811\t22\t.\t1.43200\t2.27093\t1.31249\t377\r\n",
      "chrI\t113337\t114374\tPeak_1054\t369\t.\t3.76250\t36.94333\t35.13755\t145\r\n",
      "chrI\t113337\t114374\tPeak_3483\t73\t.\t1.99356\t7.39529\t6.17374\t708\r\n",
      "chrI\t113337\t114374\tPeak_3694\t61\t.\t1.88125\t6.16174\t4.98351\t411\r\n",
      "chrI\t114606\t114837\tPeak_1041\t375\t.\t3.79058\t37.53549\t35.72075\t111\r\n",
      "chrI\t129068\t129274\tPeak_2465\t148\t.\t2.55513\t14.88796\t13.47084\t84\r\n",
      "chrI\t130158\t130752\tPeak_3177\t94\t.\t2.16203\t9.42043\t8.13851\t228\r\n",
      "chrI\t130158\t130752\tPeak_3281\t87\t.\t2.10588\t8.72283\t7.46047\t424\r\n",
      "chrI\t138986\t139388\tPeak_1672\t241\t.\t3.01769\t24.11693\t22.52225\t239\r\n"
     ]
    }
   ],
   "source": [
    "#Now, iterate through the list of narrowPeak files and concatenate them into a single master peak list. \n",
    "for f in `cat narrowPeak_files.txt`\n",
    "do \n",
    "    zcat $f >> all.peaks.bed\n",
    "done\n",
    "\n",
    "#sanity check the all.peaks.bed file \n",
    "head all.peaks.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrI\t0\t638\tPeak_557\t168\t.\t8.54555\t16.87634\t14.86262\t203\r\n",
      "chrI\t0\t638\tPeak_740\t112\t.\t6.51090\t11.29750\t9.43357\t515\r\n",
      "chrI\t12\t638\tPeak_1260\t184\t.\t3.49583\t18.41892\t16.80362\t169\r\n",
      "chrI\t12\t638\tPeak_1118\t213\t.\t3.74915\t21.35185\t19.68702\t495\r\n",
      "chrI\t18\t779\tPeak_941\t704\t.\t4.31909\t70.49263\t68.69950\t179\r\n",
      "chrI\t18\t779\tPeak_811\t803\t.\t4.60832\t80.38562\t78.52775\t481\r\n",
      "chrI\t33\t649\tPeak_1500\t424\t.\t3.67656\t42.43305\t40.86024\t156\r\n",
      "chrI\t33\t649\tPeak_1170\t576\t.\t4.25102\t57.68048\t55.99532\t471\r\n",
      "chrI\t37\t779\tPeak_2004\t418\t.\t3.60449\t41.88854\t40.40920\t169\r\n",
      "chrI\t37\t779\tPeak_1423\t633\t.\t4.38323\t63.32488\t61.68840\t464\r\n"
     ]
    }
   ],
   "source": [
    "#sort the concatenated file \n",
    "bedtools sort -i all.peaks.bed > all.peaks.sorted.bed \n",
    "\n",
    "head all.peaks.sorted.bed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrI\t0\t781\r\n",
      "chrI\t6332\t6549\r\n",
      "chrI\t9138\t9609\r\n",
      "chrI\t20611\t21197\r\n",
      "chrI\t28155\t29092\r\n",
      "chrI\t29173\t30197\r\n",
      "chrI\t31527\t31972\r\n",
      "chrI\t32456\t36256\r\n",
      "chrI\t39017\t39243\r\n",
      "chrI\t42035\t42993\r\n"
     ]
    }
   ],
   "source": [
    "#merge the sorted, concatenated fileto join overlapping peaks \n",
    "bedtools merge -i all.peaks.sorted.bed > all_merged.peaks.bed \n",
    "\n",
    "head all_merged.peaks.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrI\t0\t781\t1\r\n",
      "chrI\t6332\t6549\t2\r\n",
      "chrI\t9138\t9609\t3\r\n",
      "chrI\t20611\t21197\t4\r\n",
      "chrI\t28155\t29092\t5\r\n",
      "chrI\t29173\t30197\t6\r\n",
      "chrI\t31527\t31972\t7\r\n",
      "chrI\t32456\t36256\t8\r\n",
      "chrI\t39017\t39243\t9\r\n",
      "chrI\t42035\t42993\t10\r\n"
     ]
    }
   ],
   "source": [
    "#Finally, we use the awk command to add row numbers to the merged peak file, such that each peak has a unique identifier. \n",
    "\n",
    "#We cannot do this 'in place', so we use an intermediate output file \n",
    "awk  -v OFS='\\t' '{print $0,NR}' all_merged.peaks.bed > o.tmp\n",
    "mv o.tmp all_merged.peaks.bed\n",
    "\n",
    "head all_merged.peaks.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating read count and fold change matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to calculate the signal strength in each sample at the genomic regions in **all_merged.peaks.bed**. The ATAC-seq pipeline generates genome-wide fold change signal tracks for each sample that can be used for this calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /signal/macs2/rep1/: No such file or directory\r\n",
      "\r\n",
      "ls: cannot access /signal/macs2/rep1/: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "ls $outdir1/signal/macs2/rep1/\n",
    "echo \"\"\n",
    "ls $outdir2/signal/macs2/rep1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the **bigWigAverageOverBed** utility to computue the mean signal from the pval tracks and the mean signal from the fold change tracks for each genomic region in each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigWigAverageOverBed v2 - Compute average score of big wig over each bed, which may have introns.\r\n",
      "usage:\r\n",
      "   bigWigAverageOverBed in.bw in.bed out.tab\r\n",
      "The output columns are:\r\n",
      "   name - name field from bed, which should be unique\r\n",
      "   size - size of bed (sum of exon sizes\r\n",
      "   covered - # bases within exons covered by bigWig\r\n",
      "   sum - sum of values over all bases covered\r\n",
      "   mean0 - average over bases with non-covered bases counting as zeroes\r\n",
      "   mean - average over just covered bases\r\n",
      "Options:\r\n",
      "   -stats=stats.ra - Output a collection of overall statistics to stat.ra file\r\n",
      "   -bedOut=out.bed - Make output bed that is echo of input bed but with mean column appended\r\n",
      "   -sampleAroundCenter=N - Take sample at region N bases wide centered around bed item, rather\r\n",
      "                     than the usual sample in the bed item.\r\n",
      "   -minMax - include two additional columns containing the min and max observed in the area.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "bigWigAverageOverBed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/scratch/training_camp/aggregate_analysis/whi5-SCE-Rep1/signal/macs2/rep1/whi5-SCE-Rep1_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCD-Rep2_out/signal/macs2/rep1/WT-SCD-Rep2_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCD-Rep2/signal/macs2/rep1/cln3-SCD-Rep2_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCE-Rep2/signal/macs2/rep1/cln3-SCE-Rep2_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/whi5-cln3-SCE-Rep2/signal/macs2/rep1/whi5-cln3-SCE-Rep2_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCE-0_6MNaCl-Rep1/signal/macs2/rep1/WT-SCE-0_6MNaCl-Rep1_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCD-Rep1/signal/macs2/rep1/cln3-SCD-Rep1_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCD-0_6MNaCl-Rep2/signal/macs2/rep1/WT-SCD-0_6MNaCl-Rep2_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCE-0_6MNaCl-Rep2/signal/macs2/rep1/cln3-SCE-0_6MNaCl-Rep2_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCE-Rep2/signal/macs2/rep1/WT-SCE-Rep2_R1_001.PE2SE.nodup.tn5.pf.fc.signal.bigwig\r\n"
     ]
    }
   ],
   "source": [
    "#First, we find all the fold change bigWig files\n",
    "cd $WORK_DIR\n",
    "find $AGGREGATE_ANALYSIS_DIR  -name \"*fc*bigwig\" > all.fc.bigwig\n",
    "head all.fc.bigwig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whi5-SCE-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "WT-SCD-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "cln3-SCD-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "cln3-SCE-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "whi5-cln3-SCE-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "WT-SCE-0_6MNaCl-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "cln3-SCD-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "WT-SCD-0_6MNaCl-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "cln3-SCE-0_6MNaCl-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "WT-SCE-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "whi5-SCE-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "whi5-cln3-SCE-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "WT-SCE-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "WT-SCE-0_6MNaCl-Rep2_R1_001\r\n",
      "processing chromosomes................\r\n",
      "WT-SCD-0_6MNaCl-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "cln3-SCE-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "WT-SCD-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "cln3-SCE-0_6MNaCl-Rep1_R1_001\r\n",
      "processing chromosomes................\r\n",
      "cln3-SCD-Rep1_R1_001\tcln3-SCD-Rep2_R1_001\tcln3-SCE-0_6MNaCl-Rep1_R1_001\tcln3-SCE-0_6MNaCl-Rep2_R1_001\tcln3-SCE-Rep1_R1_001\tcln3-SCE-Rep2_R1_001\twhi5-cln3-SCE-Rep1_R1_001\twhi5-cln3-SCE-Rep2_R1_001\twhi5-SCE-Rep1_R1_001\twhi5-SCE-Rep2_R1_001\tWT-SCD-0_6MNaCl-Rep1_R1_001\tWT-SCD-0_6MNaCl-Rep2_R1_001\tWT-SCD-Rep1_R1_001\tWT-SCD-Rep2_R1_001\tWT-SCE-0_6MNaCl-Rep1_R1_001\tWT-SCE-0_6MNaCl-Rep2_R1_001\tWT-SCE-Rep1_R1_001\tWT-SCE-Rep2_R1_001\r\n",
      "1.2082\t1.25879\t2.07344\t2.9692\t2.30141\t2.62036\t1.86505\t2.87168\t2.52725\t0.965167\t2.73239\t2.67876\t1.90212\t1.74266\t2.82429\t2.64587\t6.503\t2.1628\r\n",
      "1.78946\t1.78578\t1.71822\t1.41723\t2.07408\t0.991613\t2.20631\t1.89088\t1.90687\t1.54817\t0.965532\t0.875607\t1.30748\t1.76865\t2.39724\t2.5723\t0.74938\t2.00934\r\n",
      "0.919425\t1.04169\t1.42442\t1.20006\t1.5744\t1.22962\t1.41871\t1.42797\t1.24815\t1.34926\t0.399234\t0.432705\t0.947398\t0.885702\t0.990087\t1.25556\t0.437034\t1.92736\r\n",
      "1.30906\t1.33\t1.87316\t1.53013\t1.78733\t1.42063\t1.75343\t1.94326\t1.89821\t0.893881\t1.21955\t1.90289\t1.17362\t1.65642\t2.28866\t2.16635\t2.36755\t1.68974\r\n",
      "2.05361\t2.19933\t1.27016\t1.17653\t1.56107\t1.58483\t1.71036\t1.50945\t1.326\t1.29448\t0.85632\t1.0218\t2.14143\t1.95098\t1.20479\t1.23796\t1.15235\t1.5374\r\n",
      "1.62058\t1.63262\t1.67228\t1.47503\t1.84358\t1.6812\t1.81347\t1.65736\t1.82927\t1.66342\t0.629096\t0.828475\t1.48083\t1.73587\t1.85394\t1.83819\t0.836652\t1.99762\r\n",
      "1.09965\t1.04164\t1.27423\t1.13666\t1.23196\t1.6573\t1.46369\t1.48814\t1.4237\t1.3542\t0.764356\t0.704616\t1.1596\t1.08208\t1.07885\t1.18763\t1.50574\t1.29347\r\n",
      "1.15495\t1.32104\t1.43664\t1.569\t1.28096\t1.35413\t1.25028\t1.30096\t1.36407\t1.03952\t2.00029\t1.95895\t1.30061\t1.32188\t1.6176\t1.52737\t1.76838\t1.23513\r\n",
      "1.45702\t1.73103\t1.52554\t1.34507\t1.62336\t0.888631\t1.85355\t1.37273\t1.18577\t1.40058\t1.28456\t0.995152\t1.5567\t1.90082\t1.08989\t1.12311\t1.41108\t1.88658\r\n"
     ]
    }
   ],
   "source": [
    "#Iterate through all bigWig fold change tracks to compute mean signal strength at each genomic region \n",
    "for f in `cat all.fc.bigwig`\n",
    "do\n",
    "\n",
    "    #we extract the part of the filename that corresponds to the sample name and write it as the header in the fc.signal file\n",
    "    sample_name=`basename $f | awk -F'[.]' '{print $1}'`\n",
    "    echo \"$sample_name\"\n",
    "    echo $sample_name > $sample_name.fc.signal.tmp \n",
    "    \n",
    "    \n",
    "    bigWigAverageOverBed $f all_merged.peaks.bed $sample_name.fc.signal.data.tmp \n",
    "    cut -f5 $sample_name.fc.signal.data.tmp >> $sample_name.fc.signal.tmp\n",
    "\n",
    "    #cleanup the intermediate file \n",
    "    rm $sample_name.fc.signal.data.tmp \n",
    "done\n",
    "paste *fc.signal.tmp > all.fc.txt\n",
    "#cleanup intermediate files that were generated \n",
    "rm *.tmp\n",
    "\n",
    "#examine the output \n",
    "head all.fc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the fold change data matrix, we would also like to know the number of reads that pile up at each peak region. This is useful for determining differential chromatin accessibility across samples. \n",
    "To calculate the read count matrix, we will use the **bedtools coverage** command on the *tagAlign* files generated by the processing pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/scratch/training_camp/aggregate_analysis/whi5-SCE-Rep1/align/rep1/whi5-SCE-Rep1_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCD-0_6MNaCl-Rep2/align/rep1/cln3-SCD-0_6MNaCl-Rep2_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCD-Rep2_out/align/rep1/WT-SCD-Rep2_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCD-Rep2/align/rep1/cln3-SCD-Rep2_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCE-Rep2/align/rep1/cln3-SCE-Rep2_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/whi5-cln3-SCE-Rep2/align/rep1/whi5-cln3-SCE-Rep2_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCE-0_6MNaCl-Rep1/align/rep1/WT-SCE-0_6MNaCl-Rep1_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCD-Rep1/align/rep1/cln3-SCD-Rep1_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/WT-SCD-0_6MNaCl-Rep2/align/rep1/WT-SCD-0_6MNaCl-Rep2_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n",
      "/srv/scratch/training_camp/aggregate_analysis/cln3-SCE-0_6MNaCl-Rep2/align/rep1/cln3-SCE-0_6MNaCl-Rep2_R1_001.PE2SE.nodup.tn5.no_chrM.25M.R1.tagAlign.gz\r\n"
     ]
    }
   ],
   "source": [
    "#First, we find all the tagAlign\n",
    "cd $WORK_DIR\n",
    "find $AGGREGATE_ANALYSIS_DIR  -name \"*nodup.tn5.no_chrM.25M.R1.tagAlign*\" > all.tagAlign.files.txt\n",
    "\n",
    "head all.tagAlign.files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Tool:    bedtools coverage (aka coverageBed)\r\n",
      "Version: v2.17.0\r\n",
      "Summary: Returns the depth and breadth of coverage of features from A\r\n",
      "\t on the intervals in B.\r\n",
      "\r\n",
      "Usage:   bedtools coverage [OPTIONS] -a <bed/gff/vcf> -b <bed/gff/vcf>\r\n",
      "\r\n",
      "Options: \r\n",
      "\t-abam\tThe A input file is in BAM format.\r\n",
      "\r\n",
      "\t-s\tRequire same strandedness.  That is, only counts hits in A that\r\n",
      "\t\toverlap B on the _same_ strand.\r\n",
      "\t\t- By default, overlaps are counted without respect to strand.\r\n",
      "\r\n",
      "\t-S\tRequire different strandedness.  That is, only report hits in A\r\n",
      "\t\tthat overlap B on the _opposite_ strand.\r\n",
      "\t\t- By default, overlaps are counted without respect to strand.\r\n",
      "\r\n",
      "\t-hist\tReport a histogram of coverage for each feature in B\r\n",
      "\t\tas well as a summary histogram for _all_ features in B.\r\n",
      "\r\n",
      "\t\tOutput (tab delimited) after each feature in B:\r\n",
      "\t\t  1) depth\r\n",
      "\t\t  2) # bases at depth\r\n",
      "\t\t  3) size of B\r\n",
      "\t\t  4) % of B at depth\r\n",
      "\r\n",
      "\t-d\tReport the depth at each position in each B feature.\r\n",
      "\t\tPositions reported are one based.  Each position\r\n",
      "\t\tand depth follow the complete B feature.\r\n",
      "\r\n",
      "\t-counts\tOnly report the count of overlaps, don't compute fraction, etc.\r\n",
      "\r\n",
      "\t-split\tTreat \"split\" BAM or BED12 entries as distinct BED intervals.\r\n",
      "\t\twhen computing coverage.\r\n",
      "\t\tFor BAM files, this uses the CIGAR \"N\" and \"D\" operations \r\n",
      "\t\tto infer the blocks for computing coverage.\r\n",
      "\t\tFor BED12 files, this uses the BlockCount, BlockStarts,\r\n",
      "\t\tand BlockEnds fields (i.e., columns 10,11,12).\r\n",
      "\r\n",
      "Default Output:  \r\n",
      "\t After each entry in B, reports: \r\n",
      "\t   1) The number of features in A that overlapped the B interval.\r\n",
      "\t   2) The number of bases in B that had non-zero coverage.\r\n",
      "\t   3) The length of the entry in B.\r\n",
      "\t   4) The fraction of bases in B that had non-zero coverage.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#Let's see how the bedtools coverage command works\n",
    "bedtools coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whi5-SCE-Rep1_R1_001\r\n",
      "cln3-SCD-0_6MNaCl-Rep2_R1_001\r\n",
      "WT-SCD-Rep2_R1_001\r\n",
      "cln3-SCD-Rep2_R1_001\r\n",
      "cln3-SCE-Rep2_R1_001\r\n",
      "whi5-cln3-SCE-Rep2_R1_001\r\n",
      "WT-SCE-0_6MNaCl-Rep1_R1_001\r\n",
      "cln3-SCD-Rep1_R1_001\r\n",
      "WT-SCD-0_6MNaCl-Rep2_R1_001\r\n",
      "cln3-SCE-0_6MNaCl-Rep2_R1_001\r\n",
      "WT-SCE-Rep2_R1_001\r\n",
      "whi5-SCE-Rep2_R1_001\r\n",
      "cln3-SCD-0_6MNaCl-Rep1_R1_001\r\n",
      "whi5-cln3-SCE-Rep1_R1_001\r\n",
      "WT-SCE-Rep1_R1_001\r\n",
      "WT-SCE-0_6MNaCl-Rep2_R1_001\r\n",
      "WT-SCD-0_6MNaCl-Rep1_R1_001\r\n",
      "cln3-SCE-Rep1_R1_001\r\n",
      "WT-SCD-Rep1_R1_001\r\n",
      "cln3-SCE-0_6MNaCl-Rep1_R1_001\r\n",
      "cln3-SCD-0_6MNaCl-Rep1_R1_001\tcln3-SCD-0_6MNaCl-Rep2_R1_001\tcln3-SCD-Rep1_R1_001\tcln3-SCD-Rep2_R1_001\tcln3-SCE-0_6MNaCl-Rep1_R1_001\tcln3-SCE-0_6MNaCl-Rep2_R1_001\tcln3-SCE-Rep1_R1_001\tcln3-SCE-Rep2_R1_001\twhi5-cln3-SCE-Rep1_R1_001\twhi5-cln3-SCE-Rep2_R1_001\twhi5-SCE-Rep1_R1_001\twhi5-SCE-Rep2_R1_001\tWT-SCD-0_6MNaCl-Rep1_R1_001\tWT-SCD-0_6MNaCl-Rep2_R1_001\tWT-SCD-Rep1_R1_001\tWT-SCD-Rep2_R1_001\tWT-SCE-0_6MNaCl-Rep1_R1_001\tWT-SCE-0_6MNaCl-Rep2_R1_001\tWT-SCE-Rep1_R1_001\tWT-SCE-Rep2_R1_001\r\n",
      "0\t0\t151\t191\t226\t158\t210\t127\t292\t296\t232\t188\t83\t246\t25\t182\t241\t203\t9\t244\r\n",
      "0\t0\t537\t820\t1342\t1050\t1157\t590\t1460\t1624\t1562\t713\t590\t1585\t115\t732\t2227\t2032\t90\t1230\r\n",
      "0\t0\t175\t222\t366\t251\t304\t160\t401\t483\t410\t261\t143\t379\t34\t220\t379\t383\t17\t344\r\n",
      "0\t0\t249\t309\t369\t282\t316\t189\t394\t406\t322\t314\t134\t342\t60\t370\t334\t310\t19\t410\r\n",
      "0\t0\t50\t50\t48\t37\t42\t22\t57\t65\t55\t72\t12\t49\t7\t47\t65\t64\t1\t60\r\n",
      "0\t0\t88\t115\t215\t226\t225\t129\t241\t390\t284\t118\t86\t224\t27\t164\t324\t316\t25\t249\r\n",
      "0\t0\t38\t54\t55\t35\t59\t16\t87\t79\t65\t55\t10\t22\t5\t50\t78\t84\t1\t69\r\n",
      "0\t0\t40\t60\t94\t61\t95\t38\t120\t118\t92\t106\t9\t24\t7\t53\t69\t97\t1\t144\r\n",
      "0\t0\t76\t100\t144\t90\t140\t55\t175\t206\t168\t84\t29\t123\t13\t119\t199\t193\t7\t150\r\n"
     ]
    }
   ],
   "source": [
    "#Iterate through all tagAlign files to compute read count at each peak region.  \n",
    "for f in `cat all.tagAlign.files.txt`\n",
    "do\n",
    "    sample_name=`basename $f | awk -F'[.]' '{print $1}'`\n",
    "    echo \"$sample_name\"\n",
    "    echo $sample_name > $sample_name.readcount.tmp \n",
    "    zcat $f | bedtools coverage -counts -a stdin -b all_merged.peaks.bed  | cut -f5 >>$sample_name.readcount.tmp \n",
    "done\n",
    "paste *.readcount.tmp > all.readcount.txt\n",
    "#cleanup the temporary files\n",
    "rm *.tmp\n",
    "\n",
    "#examine the output \n",
    "head all.readcount.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the counts in the first and second columns are on a different scale. This makes sense because if a particular sample had more reads to begin with, the raw counts for each peak will be higher. \n",
    "We can address this problem with sample normalization, covered in the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Finally, we add in the peak names to our counts file and fold change file so we can keep track of which row \n",
    "#corresponds to which peak. \n",
    "\n",
    "\n",
    "#add a header to the merged peak file \n",
    "sed -i '1i\\Chrom\\tStart\\tEnd\\tID' all_merged.peaks.bed\n",
    "\n",
    "#paste the peak bed file region annotation matrix to the signal matrix\n",
    "paste all_merged.peaks.bed all.fc.txt > o.tmp \n",
    "mv o.tmp all.fc.txt \n",
    "\n",
    "paste all_merged.peaks.bed all.readcount.txt > o.tmp\n",
    "mv o.tmp all.readcount.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrom\tStart\tEnd\tID\tcln3-SCD-0_6MNaCl-Rep1_R1_001\tcln3-SCD-0_6MNaCl-Rep2_R1_001\tcln3-SCD-Rep1_R1_001\tcln3-SCD-Rep2_R1_001\tcln3-SCE-0_6MNaCl-Rep1_R1_001\tcln3-SCE-0_6MNaCl-Rep2_R1_001\tcln3-SCE-Rep1_R1_001\tcln3-SCE-Rep2_R1_001\twhi5-cln3-SCE-Rep1_R1_001\twhi5-cln3-SCE-Rep2_R1_001\twhi5-SCE-Rep1_R1_001\twhi5-SCE-Rep2_R1_001\tWT-SCD-0_6MNaCl-Rep1_R1_001\tWT-SCD-0_6MNaCl-Rep2_R1_001\tWT-SCD-Rep1_R1_001\tWT-SCD-Rep2_R1_001\tWT-SCE-0_6MNaCl-Rep1_R1_001\tWT-SCE-0_6MNaCl-Rep2_R1_001\tWT-SCE-Rep1_R1_001\tWT-SCE-Rep2_R1_001\r\n",
      "chrI\t0\t781\t1\t0\t0\t151\t191\t226\t158\t210\t127\t292\t296\t232\t188\t83\t246\t25\t182\t241\t203\t9\t244\r\n",
      "chrI\t6332\t6549\t2\t0\t0\t537\t820\t1342\t1050\t1157\t590\t1460\t1624\t1562\t713\t590\t1585\t115\t732\t2227\t2032\t90\t1230\r\n",
      "chrI\t9138\t9609\t3\t0\t0\t175\t222\t366\t251\t304\t160\t401\t483\t410\t261\t143\t379\t34\t220\t379\t383\t17\t344\r\n",
      "chrI\t20611\t21197\t4\t0\t0\t249\t309\t369\t282\t316\t189\t394\t406\t322\t314\t134\t342\t60\t370\t334\t310\t19\t410\r\n",
      "chrI\t28155\t29092\t5\t0\t0\t50\t50\t48\t37\t42\t22\t57\t65\t55\t72\t12\t49\t7\t47\t65\t64\t1\t60\r\n",
      "chrI\t29173\t30197\t6\t0\t0\t88\t115\t215\t226\t225\t129\t241\t390\t284\t118\t86\t224\t27\t164\t324\t316\t25\t249\r\n",
      "chrI\t31527\t31972\t7\t0\t0\t38\t54\t55\t35\t59\t16\t87\t79\t65\t55\t10\t22\t5\t50\t78\t84\t1\t69\r\n",
      "chrI\t32456\t36256\t8\t0\t0\t40\t60\t94\t61\t95\t38\t120\t118\t92\t106\t9\t24\t7\t53\t69\t97\t1\t144\r\n",
      "chrI\t39017\t39243\t9\t0\t0\t76\t100\t144\t90\t140\t55\t175\t206\t168\t84\t29\t123\t13\t119\t199\t193\t7\t150\r\n"
     ]
    }
   ],
   "source": [
    "head all.readcount.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrom\tStart\tEnd\tID\tcln3-SCD-Rep1_R1_001\tcln3-SCD-Rep2_R1_001\tcln3-SCE-0_6MNaCl-Rep1_R1_001\tcln3-SCE-0_6MNaCl-Rep2_R1_001\tcln3-SCE-Rep1_R1_001\tcln3-SCE-Rep2_R1_001\twhi5-cln3-SCE-Rep1_R1_001\twhi5-cln3-SCE-Rep2_R1_001\twhi5-SCE-Rep1_R1_001\twhi5-SCE-Rep2_R1_001\tWT-SCD-0_6MNaCl-Rep1_R1_001\tWT-SCD-0_6MNaCl-Rep2_R1_001\tWT-SCD-Rep1_R1_001\tWT-SCD-Rep2_R1_001\tWT-SCE-0_6MNaCl-Rep1_R1_001\tWT-SCE-0_6MNaCl-Rep2_R1_001\tWT-SCE-Rep1_R1_001\tWT-SCE-Rep2_R1_001\r\n",
      "chrI\t0\t781\t1\t1.2082\t1.25879\t2.07344\t2.9692\t2.30141\t2.62036\t1.86505\t2.87168\t2.52725\t0.965167\t2.73239\t2.67876\t1.90212\t1.74266\t2.82429\t2.64587\t6.503\t2.1628\r\n",
      "chrI\t6332\t6549\t2\t1.78946\t1.78578\t1.71822\t1.41723\t2.07408\t0.991613\t2.20631\t1.89088\t1.90687\t1.54817\t0.965532\t0.875607\t1.30748\t1.76865\t2.39724\t2.5723\t0.74938\t2.00934\r\n",
      "chrI\t9138\t9609\t3\t0.919425\t1.04169\t1.42442\t1.20006\t1.5744\t1.22962\t1.41871\t1.42797\t1.24815\t1.34926\t0.399234\t0.432705\t0.947398\t0.885702\t0.990087\t1.25556\t0.437034\t1.92736\r\n",
      "chrI\t20611\t21197\t4\t1.30906\t1.33\t1.87316\t1.53013\t1.78733\t1.42063\t1.75343\t1.94326\t1.89821\t0.893881\t1.21955\t1.90289\t1.17362\t1.65642\t2.28866\t2.16635\t2.36755\t1.68974\r\n",
      "chrI\t28155\t29092\t5\t2.05361\t2.19933\t1.27016\t1.17653\t1.56107\t1.58483\t1.71036\t1.50945\t1.326\t1.29448\t0.85632\t1.0218\t2.14143\t1.95098\t1.20479\t1.23796\t1.15235\t1.5374\r\n",
      "chrI\t29173\t30197\t6\t1.62058\t1.63262\t1.67228\t1.47503\t1.84358\t1.6812\t1.81347\t1.65736\t1.82927\t1.66342\t0.629096\t0.828475\t1.48083\t1.73587\t1.85394\t1.83819\t0.836652\t1.99762\r\n",
      "chrI\t31527\t31972\t7\t1.09965\t1.04164\t1.27423\t1.13666\t1.23196\t1.6573\t1.46369\t1.48814\t1.4237\t1.3542\t0.764356\t0.704616\t1.1596\t1.08208\t1.07885\t1.18763\t1.50574\t1.29347\r\n",
      "chrI\t32456\t36256\t8\t1.15495\t1.32104\t1.43664\t1.569\t1.28096\t1.35413\t1.25028\t1.30096\t1.36407\t1.03952\t2.00029\t1.95895\t1.30061\t1.32188\t1.6176\t1.52737\t1.76838\t1.23513\r\n",
      "chrI\t39017\t39243\t9\t1.45702\t1.73103\t1.52554\t1.34507\t1.62336\t0.888631\t1.85355\t1.37273\t1.18577\t1.40058\t1.28456\t0.995152\t1.5567\t1.90082\t1.08989\t1.12311\t1.41108\t1.88658\r\n"
     ]
    }
   ],
   "source": [
    "head all.fc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now generated a read count matrix and a fold change signal peak regions in our dataset. \n",
    "This completes the basic data processing pipeline. \n",
    "Now, on to drawing conclusions about our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
